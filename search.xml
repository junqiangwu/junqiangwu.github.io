<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[TF_Object_Detection API 训练自己模型]]></title>
    <url>%2F2019%2F03%2F10%2FTF-Object-Detection-API-%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[安装Tensorflow_Object_detection_API 依赖库 1Protobuf 、Python-tk、Pillow 1.0、lxml、tf Slim、Jupyter notebook、Matplotlib、Tensorflow、Cython、cocoapi 具体请参考： https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md 安装依赖库：(具体可参考官方文档) 下载源码： 12345678910111213git clone https://github.com/tensorflow/modelssudo apt-get install protobuf-compiler python-pil python-lxml python-tksudo pip3 install Cythonsudo pip3 install jupytersudo pip3 install matplotlib#或者使用pip安装：sudo pip install Cythonsudo pip install pillowsudo pip install lxmlsudo pip install jupytersudo pip install matplotlib 如果使用COCO作为评价指标的话，需要接入coco的pythonApi， 1234git clone https://github.com/cocodataset/cocoapi.gitcd cocoapi/PythonAPImakecp -r pycocotools &lt;path_to_tensorflow&gt;/models/research/ 编译项目From tensorflow/models/research/ 首先protoc编译项目，然后添加环境变量 Mac端： ~./bash_profile 1234567protoc object_detection/protos/*.proto --python_out=.export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim# 如果protoc版本过低，请对应环境下载 https://link.zhihu.com/?target=https%3A//github.com/google/protobuf/releasessudo cp bin/protoc /usr/bin/protoc 再次尝试编译、添加环境 测试安装Ok： python3 object_detection/builders/model_builder_test.py 如果返回Ok 则安装成功，运行setuppython3 setup.py install 制作自己的数据集 并使用API传输训练利用labelImag标注数据，生成xml信息，利用Xml-to-csv.py转换成voc的格式，xml-to-csv脚本： 注意按照自己的文件结构对应修改，我的结构： 123456789101112-train_data/ --...-images/ --test/ ---testingimages.jpg ---image.xml --train/ ---testingimages.jpg ---image.xml --..yourimages.jpg-xml_to_csv.py 1234567891011121314151617181920212223242526272829303132333435import osimport globimport pandas as pdimport xml.etree.ElementTree as ETdef xml_to_csv(path): xml_list = [] for xml_file in glob.glob(path + &apos;/*.xml&apos;): tree = ET.parse(xml_file) root = tree.getroot() for member in root.findall(&apos;object&apos;): value = (root.find(&apos;filename&apos;).text, int(root.find(&apos;size&apos;)[0].text), int(root.find(&apos;size&apos;)[1].text), member[0].text, int(member[4][0].text), int(member[4][1].text), int(member[4][2].text), int(member[4][3].text) ) xml_list.append(value) column_name = [&apos;filename&apos;, &apos;width&apos;, &apos;height&apos;, &apos;class&apos;, &apos;xmin&apos;, &apos;ymin&apos;, &apos;xmax&apos;, &apos;ymax&apos;] xml_df = pd.DataFrame(xml_list, columns=column_name) return xml_dfdef main(): for directory in [&apos;train&apos;,&apos;test&apos;]: image_path = os.path.join(os.getcwd(), &apos;images/&#123;&#125;&apos;.format(directory)) xml_df = xml_to_csv(image_path) xml_df.to_csv(&apos;train_data/&#123;&#125;_labels.csv&apos;.format(directory), index=None) print(&apos;Successfully converted xml to csv.&apos;)main() 将Csv格式的图片信息转换为tf_record格式，提供API训练 首先将上述的images、data移到model/research/object_detedtion文件夹下：利用generate_tfrecord.py转换格式 需要修改 返回的类别和名称 以及文件路径名 https://github.com/junqiangwu/My_Tensorflow/blob/master/object-detection/generate_tfrecord.py From model/research/object_detection/ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798from __future__ import division from __future__ import print_function from __future__ import absolute_import import os import io import pandas as pd import tensorflow as tf from PIL import Image from object_detection.utils import dataset_util from collections import namedtuple, OrderedDict flags = tf.app.flags flags.DEFINE_string(&apos;csv_input&apos;, &apos;&apos;, &apos;Path to the CSV input&apos;) flags.DEFINE_string(&apos;output_path&apos;, &apos;&apos;, &apos;Path to output TFRecord&apos;) FLAGS = flags.FLAGS # TO-DO replace this with label map def class_text_to_int(row_label): if row_label == &apos;macncheese&apos;: return 1 else: None def split(df, group): data = namedtuple(&apos;data&apos;, [&apos;filename&apos;, &apos;object&apos;]) gb = df.groupby(group) return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)] def create_tf_example(group, path): with tf.gfile.GFile(os.path.join(path, &apos;&#123;&#125;&apos;.format(group.filename)), &apos;rb&apos;) as fid: encoded_jpg = fid.read() encoded_jpg_io = io.BytesIO(encoded_jpg) image = Image.open(encoded_jpg_io) width, height = image.size filename = group.filename.encode(&apos;utf8&apos;) image_format = b&apos;jpg&apos; xmins = [] xmaxs = [] ymins = [] ymaxs = [] classes_text = [] classes = [] for index, row in group.object.iterrows(): xmins.append(row[&apos;xmin&apos;] / width) xmaxs.append(row[&apos;xmax&apos;] / width) ymins.append(row[&apos;ymin&apos;] / height) ymaxs.append(row[&apos;ymax&apos;] / height) classes_text.append(row[&apos;class&apos;].encode(&apos;utf8&apos;)) classes.append(class_text_to_int(row[&apos;class&apos;])) tf_example = tf.train.Example(features=tf.train.Features(feature=&#123; &apos;image/height&apos;: dataset_util.int64_feature(height), &apos;image/width&apos;: dataset_util.int64_feature(width), &apos;image/filename&apos;: dataset_util.bytes_feature(filename), &apos;image/source_id&apos;: dataset_util.bytes_feature(filename), &apos;image/encoded&apos;: dataset_util.bytes_feature(encoded_jpg), &apos;image/format&apos;: dataset_util.bytes_feature(image_format), &apos;image/object/bbox/xmin&apos;: dataset_util.float_list_feature(xmins), &apos;image/object/bbox/xmax&apos;: dataset_util.float_list_feature(xmaxs), &apos;image/object/bbox/ymin&apos;: dataset_util.float_list_feature(ymins), &apos;image/object/bbox/ymax&apos;: dataset_util.float_list_feature(ymaxs), &apos;image/object/class/text&apos;: dataset_util.bytes_list_feature(classes_text), &apos;image/object/class/label&apos;: dataset_util.int64_list_feature(classes), &#125;)) return tf_example def main(_): writer = tf.python_io.TFRecordWriter(FLAGS.output_path) path = os.path.join(os.getcwd(), &apos;images&apos;) examples = pd.read_csv(FLAGS.csv_input) grouped = split(examples, &apos;filename&apos;) num=0 for group in grouped: num+=1 tf_example = create_tf_example(group, path) writer.write(tf_example.SerializeToString()) if(num%100==0): #每完成100个转换，打印一次 print(num) writer.close() output_path = os.path.join(os.getcwd(), FLAGS.output_path) print(&apos;Successfully created the TFRecords: &#123;&#125;&apos;.format(output_path)) if __name__ == &apos;__main__&apos;: tf.app.run() 1234python3 generate_tfrecord.py --csv_input=train_data/train_labels.csv --output_path=train.record python3 generate_tfrecord.py --csv_input=train_data/test_labels.csv --output_path=test.record 会在object_detection目录下生成两个.record文件，将它移到train_data目录下，train_data目录下包含：两个csv 和 两个 .record 在object_detection目录下:123456789101112-images/ --test/ ---testingimages.jpg --train/ ---testingimages.jpg --..yourimages.jpg -train_data --train_labels.csv --test_labels.csv --train.record --test.record 下载预训练模型，配置网络结构信息：12345678wget http://download.tensorflow.org/models/object_detection/ ssd_mobilenet_v1_coco_11_06_2017.tar.gzmkdir training 在training文件夹下编写训练数据标签：object_detection.pbtxt item &#123; id: 1 name: &apos;macncheese&apos; #物品类别 &#125; 从object_detection/samples/config/ssd_mobilenet_v1_pets.config移到training文件下：并作出修改： num_class: 1 batch_size: 24 fine_tune_checkpoint: &quot;ssd_mobilenet_v1_coco_11_06_2017/model.ckpt&quot; 123456train_input_reader: &#123; tf_record_input_reader &#123; input_path: &quot;train_data/train.record&quot; &#125; label_map_path: &quot;training/object-detection.pbtxt&quot; &#125; 最后在object_detection文件夹下：运行命令： 1python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config train_dir: 训练输出文件的路径 pipeline_config: 网络配置文件的路径 测试输出模型的准确性 利用.py 转换 .pb From model/research/object_detection 123456python3 export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssd_mobilenet_v1_pets.config --trained_checkpoint_prefix training/model.ckpt-388 --output_directory mac_n_cheese_inference_graph input_type : 保持一致 pipeline: 网络结构配置图 train_checkpoint: ckpt模型保存路径 既上面训练路径的设置位置 out: 输出文件 ####最后利用jupyter notebook加载pb模型进行测试1234567891011121314#修改object_detection_tutorial.ipynb# What model to download.MODEL_NAME = &apos;mac_n_cheese_inference_graph&apos;#Path to frozen detection graph. This is the actual model that is used for the object detection.PATH_TO_CKPT = MODEL_NAME + &apos;/frozen_inference_graph.pb&apos;# List of the strings that is used to add correct label for each box.PATH_TO_LABELS = os.path.join(&apos;training&apos;, &apos;object-detection.pbtxt&apos;)NUM_CLASSES = 1#删除downloand程序，修改加载测试图片的路径，运行即可 所有的配置文件在： https://github.com/junqiangwu/My_Tensorflow/tree/master/object-detection]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mxnet2Caffe]]></title>
    <url>%2F2019%2F03%2F10%2FMxnet2Caffe%2F</url>
    <content type="text"><![CDATA[Mxnet2Caffe 将mxnet静态图symbol转换为caffe的prototxt文本，支持大部分op，caffe不需要的op则需要自己添加，再转换，否则会构建失败 将json转换为prototxt 利用caffe的python接口构建网络，将mxnet的参数param迁移到caffe网络中 构建caffe不支持的op 对结果进行比对 json_2_protxt json2prototxt.py prototxt_basic.py Read mxnet_json file and converte to prototxt 123456789101112131415161718192021222324252627282930313233// json 格式，只要就是op(操作节点和辅助节点null) name attr(参数列表) inputs(输入列表list) &#123; "op": "Activation", "name": "part_0_stage1_unit1_relu1", "attrs": &#123;"act_type": "relu"&#125;, "inputs": [[14, 0, 0]] &#125;, &#123; "op": "null", "name": "part_0_stage1_unit1_conv1_weight", "attrs": &#123; "kernel": "(3, 3)", "no_bias": "True", "num_filter": "64", "pad": "(1, 1)", "stride": "(1, 1)", "workspace": "256" &#125;, "inputs": [] &#125;, &#123; "op": "Convolution", "name": "part_0_stage1_unit1_conv1", "attrs": &#123; "kernel": "(3, 3)", "no_bias": "True", "num_filter": "64", "pad": "(1, 1)", "stride": "(1, 1)", "workspace": "256" &#125;, "inputs": [[15, 0, 0], [16, 0, 0]] &#125;, 读取json文件，并存储相应信息12345678910111213141516171819202122232425262728293031323334353637with open(args.mx_json) as json_file: jdata = json.load(json_file)with open(args.cf_prototxt, "w") as prototxt_file: for i_node in range(0,len(jdata['nodes'])): #logging.info("i_node[%d],'name' %s" %(i_node,jdata['nodes'][i_node]['name'])) node_i = jdata['nodes'][i_node] # 如果当前节点是辅助节点或输入节点(只转换操作节点) 则跳过 if str(node_i['op']) == 'null' and str(node_i['name']) != 'data': continue ''' logging.info('%d, \top:%s, name:%s -&gt; %s'.%(i_node,node_i['op'].ljust(20), node_i['name'].ljust(30), node_i['name']).ljust(20)) ''' ##node[i]个节点 存在的信息 op name param input info = node_i info['top'] = info['name'] info['bottom'] = [] info['params'] = [] # 遍历当前节点的输入 存储辅助参数 for input_idx_i in node_i['inputs']: # jdata['nodes'][input_idx_i[0]] jdana['nodes'][input_index] input_i = jdata['nodes'][input_idx_i[0]] #存储所有输入节点 if str(input_i['op']) != 'null' or (str(input_i['name']) == 'data'): info['bottom'].append(str(input_i['name'])) if str(input_i['op']) == 'null': info['params'].append(str(input_i['name'])) if not str(input_i['name']).startswith(str(node_i['name'])): logging.info(' use shared weight -&gt; %s'% str(input_i['name'])) info['share'] = True write_node(prototxt_file, info) 写prototxt文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# 转换 Convolution 节点操作def Convolution(txt_file, info): if info['attrs']['no_bias'] == 'True': bias_term = 'false' else: bias_term = 'true' txt_file.write('layer &#123;\n') txt_file.write(' bottom: "%s"\n' % info['bottom'][0]) txt_file.write(' top: "%s"\n' % info['top']) txt_file.write(' name: "%s"\n' % info['top']) txt_file.write(' type: "Convolution"\n') txt_file.write(' convolution_param &#123;\n') txt_file.write(' num_output: %s\n' % info['attrs']['num_filter']) txt_file.write(' kernel_size: %s\n' % info['attrs']['kernel'].split('(')[1].split(',')[0]) # TODO if 'pad' not in info['attrs']: logging.info('miss Conv_pad, make pad default: 0 ') txt_file.write(' pad: %s\n' % 0) # TODO else: txt_file.write(' pad: %s\n' % info['attrs']['pad'].split('(')[1].split(',')[0]) # TODO# txt_file.write(' group: %s\n' % info['attrs']['num_group']) txt_file.write(' stride: %s\n' % info['attrs']['stride'].split('(')[1].split(',')[0]) txt_file.write(' bias_term: %s\n' % bias_term) txt_file.write(' &#125;\n') if 'share' in info.keys() and info['share']: txt_file.write(' param &#123;\n') txt_file.write(' name: "%s"\n' % info['params'][0]) txt_file.write(' &#125;\n') txt_file.write('&#125;\n') txt_file.write('\n')# -------根据op操作，完善相应的转换函数-----------# 目前包含Conv Pool DepthConv BN Act ele_add Concat FC Reshape etc. def write_node(txt_file, info): if 'label' in info['name']: return if info['op'] == 'null' and info['name'] == 'data': data(txt_file, info) elif info['op'] == 'Convolution': Convolution(txt_file, info) elif info['op'] == 'ChannelwiseConvolution': ChannelwiseConvolution(txt_file, info) elif info['op'] == 'BatchNorm': BatchNorm(txt_file, info) elif info['op'] == 'Activation': Activation(txt_file, info)# elif info['op'] == 'ElementWiseSum': elif info['op'] == 'elemwise_add': ElementWiseSum(txt_file, info) elif info['op'] == '_Plus': ElementWiseSum(txt_file, info) elif info['op'] == 'Concat': Concat(txt_file, info) elif info['op'] == 'Pooling':# Pooling(txt_file, info) Pooling_global(txt_file, info) elif info['op'] == 'Flatten': Flatten(txt_file, info) elif info['op'] == 'FullyConnected': FullyConnected(txt_file, info) elif info['op'] == 'SoftmaxOutput': SoftmaxOutput(txt_file, info) elif info['op'] == 'Cast': Cast(txt_file, info) elif info['op'] == 'SliceChannel': SliceChannel(txt_file, info) elif info['op'] == 'L2Normalization': L2Normalization(txt_file, info) elif info['op'] == 'Reshape': Reshape(txt_file,info) elif info['op'] == 'broadcast_mul': broadcast_mul(txt_file,info) else: logging.warn("Unknown mxnet op: %s" %info['op']) 利用caffe的python接口，构建网络，并迁移mxnet的网络参数1.mxnet2caffe.py Read mxnet_model params_dict and converte to .caffemodel 转换的时候如果存在caffe不支持的op，需要自己添加自定义层，否则在构建网络时，会error，本工程添加了broadcast_mul层caffe添加自定义层的介绍比较多，就跳过了 根据mxnet的API (load) 加载param文件的所有参数字典12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152try: import caffeexcept ImportError: import os, sys sys.path.append("/home/***/codes/mx2caffe/caffe/python/") import caffe#读取全部param 参数字典 _, arg_params, aux_params = mx.model.load_checkpoint(args.mx_model, args.mx_epoch)all_keys = arg_params.keys() + aux_params.keys()# 利用caffe的python接口，读取刚转换的proto构建网络，net = caffe.Net(args.cf_prototxt, caffe.TRAIN)for i_key,key_i in enumerate(all_keys): try: if 'data' is key_i: pass # 在mxnet字典中，存有caffe不需要的后缀，_weight _bias # 需要确认caffe的参数保存顺序 [0]是weight [1]是bias 其它op 类似查看proto结构设计 elif '_weight' in key_i: key_caffe = key_i.replace('_weight','') net.params[key_caffe][0].data.flat = arg_params[key_i].asnumpy().flat elif '_bias' in key_i: key_caffe = key_i.replace('_bias','') net.params[key_caffe][1].data.flat = arg_params[key_i].asnumpy().flat elif '_gamma' in key_i: key_caffe = key_i.replace('_gamma','_scale') net.params[key_caffe][0].data.flat = arg_params[key_i].asnumpy().flat elif '_beta' in key_i: key_caffe = key_i.replace('_beta','_scale') net.params[key_caffe][1].data.flat = arg_params[key_i].asnumpy().flat elif '_moving_mean' in key_i: key_caffe = key_i.replace('_moving_mean','') net.params[key_caffe][0].data.flat = aux_params[key_i].asnumpy().flat net.params[key_caffe][2].data[...] = 1 elif '_moving_var' in key_i: key_caffe = key_i.replace('_moving_var','') net.params[key_caffe][1].data.flat = aux_params[key_i].asnumpy().flat net.params[key_caffe][2].data[...] = 1 else: sys.exit("Warning! Unknown mxnet:&#123;&#125;".format(key_i)) print("% 3d | %s -&gt; %s, initialized." %(i_key, key_i.ljust(40), key_caffe.ljust(30))) except KeyError: print("\nWarning! key error mxnet:&#123;&#125;".format(key_i)) # ------------------------------------------# Finishnet.save(args.cf_model)print("\n- Finished.\n") 对转换结果进行比对确认 mxnet_test.py Debug mxnet output and you can compare the result with the converted caffemodel 使用mxnet debug， 打印需要对比的参数，并且输出指定层的结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import mxnet as mxdef load_checkpoint_single(model, param_path): arg_params = &#123;&#125; aux_params = &#123;&#125; save_dict = mx.nd.load(param_path) for k, value in save_dict.items(): arg_type, name = k.split(':', 1) if arg_type == 'arg': arg_params[name] = value if arg_type == 'aux': aux_params[name] = value else : pass model.set_params(arg_params, aux_params, allow_missing=False) arg_params, aux_params = model.get_params() return arg_params, aux_paramsfull_param_path = 'se_resnet34/base-0000.params'fmodel = mx.sym.load('se_resnet34/base-symbol.json')# 获取mxnet网络的所有layer参数all_layers = fmodel.get_internals()# 修改这里为需要输出layer的name+output即可指定层输出 ‘name_output’fmodel = all_layers['flat_output']fullmodel = mx.mod.Module(symbol=fmodel,data_names=['data'],label_names=[])img = []img = get_image_gray('before_forward.jpg')fullmodel.bind(data_shapes=[('data', (1, 1, 108, 108))], label_shapes=None, for_training=False, force_rebind=False)arg_params, aux_params = load_checkpoint_single(fullmodel, full_param_path)fullmodel.set_params(arg_params,aux_params)file1=open('se_resnet34.txt','w')tic=time.time()fullmodel.forward(Batch([mx.nd.array(img)]))prob = fullmodel.get_outputs()[0].asnumpy()prob = prob.astype(np.float64)prob = prob.reshape(-1,1)# 以特定的格式保存结果np.savetxt(file1,prob,fmt='%.12f')file1.close() 然后利用Caffe 加载刚才转换的网络，打印输出，对比结果精度，如果出现问题，则需要逐层排查，本工程在SENet网络上测试正常 工程项目地址 https://github.com/junqiangwu/Mxnet2Caffe-Tensor-RT-SEnet TODO: add caffe_plugin_layer Tensor RT load caffe_model Tensor RT supported Se_Resnet]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Mxnet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NAS (Neural Architecture Search)]]></title>
    <url>%2F2019%2F03%2F09%2FFBNET%2F</url>
    <content type="text"><![CDATA[NAS(Neural Architecture Search)FBNet Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture SearchImplementation of FBNet with MXNet paper address: https://arxiv.org/pdf/1812.03443.pdf Implemented Net: FBNet FBNet Based on Se_Resnet_50_Architecture other block_type architecture cound be easily implement by modify fbnet-symbol/block.py Code: blocks.py: Define blocks symbols FBNet.py: Define FBNet Class. FBNet_SE.py: Define FBNet Architecture based on Se_resnet_50. blocks_se.py: Define blocks symbols based on new search space,include [Resnet_50,Se,Group_Conv,Channel_shuffle,Deform_Conv] util.py: Define some functions. test.py: Run test. block_speed_test.py: test block lat in real environment(1080Ti) Differences from original paper: The last conv layer’s num_filters is repalced by feature_dim specified by paramters Use Amsoftmax, Arcface instead of FC, but you can set model_type to softamx to use fc Default input shape is 3,108,108, so the first conv layer has stride 1 instead of 2. Add BN out of blocks, and no bn inside blocks. Last conv has kernel size 3,3 Use + in loss not *. Adding gradient rising stage in cosine decaying schedule. Code in fbnet-symbom/util/CosineDecayScheduler_Grad How to train:If you want to modify the network structure or the learning rate adjustment function, you need to modify the source code,otherwise you can use this command directly: 1python test.py --gpu 0,1,2,3,4,5,6 --log-frequence 50 --model-type softmax --batch-size 32 How to retrain:When we want to train the large dataset and hope to change learning rate manually, or the machine is suddenly shutdown due to some reason,of course, we definitely hope we can continue to train model with previous trained weights. Then, your can use this cmd: 1python test.py --gpu 0,1,2,3,4,5,6 --log-frequence 50 --model-type softmax --batch-size 32 --load-model-path ./model This can load the latest model params for retrain,If you want to load the model with specific epoch,you can use –load-model-path ./model/*.params ,This means you can retrain your model from specific model. TODO: sample script, for now just save $\theta$ cosine decaying schedule lat in real environment DataParallel implementation]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F03%2F08%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Diarys</category>
      </categories>
      <tags>
        <tag>Diarys</tag>
      </tags>
  </entry>
</search>
