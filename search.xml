<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[结构体指针malloc注意]]></title>
    <url>%2F2019%2F03%2F22%2F%E7%BB%93%E6%9E%84%E4%BD%93%E6%8C%87%E9%92%88malloc%E6%B3%A8%E6%84%8F%2F</url>
    <content type="text"><![CDATA[malloc动态申请内存12345678910111213141516171819202122232425262728293031323334353637# 定义链表结构体typedef struct ListNode&#123; int val; ListNode* next; ListNode()&#123;val=0;next==NULL;&#125;&#125;ListNode;int main()&#123; # 先定义ListNode对象，再将其地址赋值给ListNode*指针，即可找到正确的数据地址 ListNode buf; ListNode* tmp = &amp;buf;// ListNode* tmp = (ListNode*)malloc(sizeof(ListNode)); tmp-&gt;val=10; # 而malloc也会申请到结构体所需的空间大小，并且返回的tmp2已经保存了申请到的堆空间地址，可以对其直接进行操作// ListNode* tmp2 = (ListNode*)malloc(sizeof(ListNode)); # 如果不适用malloc申请内存，ListNode* tmp2仅仅为指针分配了内存，却不知道它所要指向对象的空间大小，既不能对其结构体数据进行操作； ListNode* tmp2; tmp2-&gt;val=11; tmp-&gt;next = tmp2; while(tmp!=NULL)&#123; printf(&quot;ListNode: %d \t&quot;,tmp-&gt;val); tmp= tmp-&gt;next; &#125; # free 只是告诉系统，之前占用的内存可以被重新分配，但是tmp的值(指向地址)并没有改变，此时还可以通过解引用操作其原指向的地址空间 free(tmp); free(tmp2); # 置为NULL 防止野指针 tmp = NULL; tmp2 = NULL; return 0;&#125; 网上介绍在使用结构体指针变量的时候，往往容易犯一个“低级”错误。即定义一个结构体指针变量后就直接对结构体指针变量所指向的结构体成员进行操作，从而产生一些莫名其妙的错误。我们必须要给结构体指针变量赋予一个有效的结构体变量地址，才能正常操作结构体指针变量。比如： 123456789101112struct UART&#123; int a; uchar b; &#125;void main()&#123; struct UART *p; p-&gt;a = 0xXXX; p-&gt;b = 0xXX; printf(&quot;%i,%c&quot;,p-&gt;b,p-&gt;a);&#125; 这个程序输出的值将是不可预知的，因为“在程序中只是定义了一个结构体指针变量，并没有给该结构体指针变量赋一个有效值，因此该结构体变量所指向的地址将不确定，从而不能得到预期结果” 修改12345678910void main()&#123; struct UART *p; struct UART dd； p = &amp;dd； //这句一定要有，否则将出现不可预知的问题 p-&gt;a = 0xXXX; p-&gt;b = 0xXX; printf(&quot;%i,%c&quot;,p-&gt;b,p-&gt;a);&#125;# 既我之前说的，单独申明一个指针，系统仅仅分配了指针所需的内存空间，并且没有有效值，所以也就不能通过这个指针去访问成员变量！ leetcode引发的案例 Merge Two Sorted Lists 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123;public: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) &#123; # 1 申明指针，把有效地址赋给它 // ListNode dumpy(0); // ListNode* tmp=&amp;dumpy; # 2 直接申请 //ListNode* tmp = new ListNode(0); //ListNode* dump = tmp; # 3 直接申请 ListNode* tmp = (ListNode*)malloc(sizeof(ListNode)); ListNode* dump = tmp; while(l1!=NULL &amp;&amp; l2!= NULL)&#123; if(l1-&gt;val &lt;= l2-&gt;val)&#123; tmp-&gt;next = l1; l1 = l1-&gt;next; &#125;else&#123; tmp-&gt;next = l2; l2 = l2-&gt;next; &#125; tmp = tmp-&gt;next; &#125; tmp-&gt;next = l1?l1:l2; // if(l1!=NULL)&#123; // tmp-&gt;next = l1; // &#125; // if(l2!=NULL)&#123; // tmp-&gt;next = l2; // &#125; return dump-&gt;next; &#125;&#125;; 注意 malloc申请的空间，最后一定要free，并且置为NULL，防止出现野指针的使用 单纯的使用ListNode* p定义指针，只会分配指针本身的4字节大小，不会附带申请其内部数据所需的空间大小 free函数是将分配的这块内存与指针（malloc返回的指针）之间的所有关系斩断，指针变量P中存储的地址（这块内存的起始地址）值也没有发生变化，同时存储器中存储的内容也并没有发生改变，改变的只是指针对这块内存地址的所有权问题。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[face++ 面经]]></title>
    <url>%2F2019%2F03%2F21%2Fface-%E9%9D%A2%E7%BB%8F%2F</url>
    <content type="text"><![CDATA[mxnet2caffe 以及适配Tensor RT 遇到的问题 mxnet和caffe的pooling操作，在取整细节上存在不同，mxnet是下取整，而caffe是上取整，通过逐层debug确定问题源,解决在Tensor RT引擎上重新实现pooling层，替换存在取整问题的pooling层 在读取mxnet的json文件构建caffe_net时，存在不支持的op，需要自己添加相应的层实现，分别添加了 brocadcast传播、channel_shuffle 操作 在调式Tensor RT引擎时，不可以debug指定层，通过添加test_layer，进行debug调试； 经典网络的实现特点 resnet的skip squeezenet的压缩 shufflenet的group_conv以及channel_shuffle SEnet的通道权重 mobilenet的深度可分离卷积，其结构参数量、计算量的推导计算 常用loss函数设计 cross_entropy 以及 展开式 softmax,将分类器最后的输出单元经过Softmax进行数值处理，转换到(0，1)的概率表示 cross_entropy: 交叉熵表示两个概率之间的相似性 均值平方和 MSE smollh_l1 回归损失，涉及到不同尺寸框的loss权重问题， 如100pixel的预测框和10pixel的预测框，分别偏移5pixel,那么如何修改loss可以更合理，可以使用 (h - h^)/100 表示大框的权重，既大框对相同偏移量应该更加迟钝， BN操作的细节实现 BN操作的公式 以及 可学习参数和相应的作用 BN归一化的维度，以及 归一化公式 min_max_normalization 需要求的数据的最大/小值，x^ = x- x_min/(x_max-x_min) zero_mean normalization 需要求的原数据的均值和方差 x^ = (x-u)/(α^2)经过处理的数据近似正态分布，所以一般添加斜率和偏置，丰富数据的特征 优化器的公式推导 及 优劣性 SGD的公式，其中moment惯量的作用 adam的公式，当时没想起来adam的参数 对输入数据的常见操作就是很普通的操作，减均值~缩放(0.01)~翻转~裁剪等； 网络加速的措施 channel purning 通道修剪 紧凑型网络设计 稀疏矩阵 将feature map 矩阵分解，张量分解 权重量化 int8 float16 1234(1)人工设计轻量化神经网络模型；(2)基于神经网络架构搜索（Neural Architecture Search,NAS）的自动化设计神经网络；(3)CNN模型压缩；(4)基于AutoML的自动模型压缩 神经网络结构性搜索的实现 及 改进方向 重点介绍了FBNet网络的设计原理 及 mxnet的复现存在的问题，如多参数不同步更新、多卡加速训练存在的资源分配不均匀问题、学习率方法的优化(loss崩掉)； 介绍了FLOPs和实际延迟存在的区别，介绍了新的loss设计 介绍了搜索空间设计 NN方向的5个重点model data optimiter loss metric 本科竞赛的相关经历算法题求最长递增子序列 当时给的解决方法，是使用栈进行遍历，寻找满足递增的最小下一个元素，最后求栈容量实现sqrt函数 当时使用二分查找法解决，首先根据输入x，确定搜索区间，然后根据精度要求，不断调整区间，找到满足精度的点(存在的问题，确定区间大，没有很好的限制搜索区间，可以利用y=x 和 y= x^1/2 的曲线，确定更小的搜索空间)]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二分法 牛顿法 求sqrt]]></title>
    <url>%2F2019%2F03%2F21%2F%E4%BA%8C%E5%88%86%E6%B3%95-%E7%89%9B%E9%A1%BF%E6%B3%95-%E6%B1%82sqrt%2F</url>
    <content type="text"><![CDATA[使用二分法 首先确定二分法查找的首尾区间，然后根据abs(mid^2-target)&lt;eps的误差进行区间的移动，寻找满足精度的位置 存在的问题: 第一步寻找合适的搜索区间，我们从函数曲线上可以看出，y=x和y=√x在x=1时交集； 当待开根号数在(0,1)之间时，搜索区间也在(0,1)，当待开根号数tar&gt;1时，区间在[1,x] 实现 12345678910111213141516171819202122232425float found(float x,float eps,float s,float e)&#123; float mid = s+(e-s)/2.0; float tmp = mid*mid - x; if(abs(tmp) &lt;= err)&#123; return mid; &#125; if(tmp &gt;0)&#123; return found(x,eps,s,mid); &#125;else&#123; return found(x,eps,mid,e); &#125;&#125;float sqrt(float x,float eps)&#123; if (x&lt;0) return -1; if (x==0) return 0; if(0&lt;x &amp;&amp; x&lt;1)&#123; return found(x,eps,0.,1.); &#125;else&#123; return found(x,eps,1,x); &#125; &#125; 二分法的非递归实现1234567891011121314151617float found(float x,float eps,float s,float e)&#123; float mid = (e+s)/2.0; float tmp = mid*mid - x; while(abs(tmp) &gt; eps)&#123; printf(&quot;cnt %d %f %f %f \n &quot;,cnt,s,e,mid); if(tmp&gt;0)&#123; e = mid; &#125;else&#123; s = mid; &#125; mid=(s+e)/2; tmp = mid*mid - x; &#125; return mid;&#125; 使用牛顿迭代法 仔细思考一下就能发现，我们需要解决的问题可以简单化理解。 从函数意义上理解：我们是要求函数f(x) = x²，使f(x) = num的近似解，即x² - num = 0的近似解。 从几何意义上理解：我们是要求抛物线g(x) = x² - num与x轴交点（g(x) = 0）最接近的点。 实现 12345678910111213141516float NewTown(float x,float eps)&#123; float x0,x1= x/2.0; int cnt=0; while(abs(x1-x0) &gt;= eps)&#123; x0 = x1; printf(&quot;cnt: %d %f \n &quot;,cnt,x0); x1 = x0 - (x0*x0-x)/(2.0*x0);// x1 = 1.0/2*(x0+x/x0); cnt++; &#125; return x1;&#125; 使用牛顿迭代法求多项式的一个根12定区间，找中点，中值计算两边看。 同号去，异号算，零点落在异号间。 实现123456789101112131415161718float NewTown2()&#123; float x,x1=1; int a=1,b=2,c=3,d=4; float f,f1; while(abs(x1-x) &gt;0.001)&#123; x=x1; f = ((a*x+b)*x+c)*x + d; f1 = (3*a*x+2*b)*x+c; x1 = x - f/f1; &#125; printf(&quot;newtown2 %.10f&quot;,x1); return x1;&#125; 牛顿迭代法 五次及以上多项式方程没有根式解（就是没有像二次方程那样的万能公式) 牛顿迭代法（Newton’s method），它是牛顿在17世纪提出的一种在实数域和复数域上近似求解方程的方法。 切线是曲线的线性逼近 求高阶方程式的近似解， 比如我们要开平方根，则可以转换为求x^2 - a = 0的实数根，根据x_n+1 = x_n - f(x_n)/f’(x_n) ,不断迭代新的切线，直到找到近似解，f(x)和x轴的交点 不收敛的情况：驻点起始点不幸选择了驻点，从几何上看切线根本没有根。 越来越远离的不收敛 循环震荡的不收敛 不能完整求出所有的根 总结应用牛顿-拉弗森方法，要注意以下问题：函数在整个定义域内最好是二阶可导的起始点对求根计算影响重大，可以增加一些别的判断手段进行试错 牛顿法求极值 梯度下降求极值其实牛顿迭代法也可以很方便的求极值，只要x=x−f’(x)/f”(x)这样求的就是，f’(x)与x轴的交点，既导数的零点，也即是f(x)的极值点]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树]]></title>
    <url>%2F2019%2F03%2F13%2F%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[1.]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL]]></title>
    <url>%2F2019%2F03%2F12%2FSTL%2F</url>
    <content type="text"><![CDATA[C++序列式容器 array&lt;T,N&gt;(数组容器)是一个长度固定的序列，有N个T类型的对象，不能增加或删除元素 vector(向量容器)是一个长度可变的序列，用来存放 T 类型的对象。必要时，可以自动增加容量，但只能在序列的末尾高效地增加或删除元素 deque(双向队列容器)是一个长度可变的、可以自动增长的序列，在序列的两端都不能高效地增加或删除元素 list(链表容器)是一个长度可变的、由 T 类型对象组成的序列，它以双向链表的形式组织元素，在这个序列的任何地方都可以高效地增加或删除元素。 forward list(正向链表容器)它以单链表的形式组织元素，是一类比链表容器快、更节省内存的容器，但是它内部的元素只能从第一个元素开始访问 Vector vector 容器可以方便、灵活地代替数组array。在大多数时候，都可以用vector 代替数组存放元素,vector 在扩展容量,以及在序列内部删除或添加元素时会产生一些开销；但大多数情况下,代码不会明显变慢. ListStringMap 在关联容器中，对象的位置取决于和它关联的键的值。键可以是基本类型，也可以是类类型。字符串经常被用来作为键，如果想要保存姓名和地址的记录，就可以这么使用 HashSet]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>STL</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法随笔]]></title>
    <url>%2F2019%2F03%2F11%2F%E7%AE%97%E6%B3%95%E9%9A%8F%E7%AC%94%2F</url>
    <content type="text"><![CDATA[##算法随笔 1.原地删除重复的数字 给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。 12345给定 nums = [0,0,1,1,1,2,2,3,3,4],函数应该返回新的长度 5, 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4。你不需要考虑数组中超出新长度后面的元素。 实现12345678910111213int remove_duplicates(int a[],int size)&#123; int index = 0; for (int i=0;i&lt;size;i++)&#123; // 一直寻找到不重复的元素，进行交换，index+1 if(a[index] != a[i])&#123; index++; a[index] = a[i]; &#125; &#125; index++; return index;&#125; 2.数组中出现次数超过一半的元素 数组(无序)中有一个数字出现的次数超过了数组长度的一半，找出这个数字。 解法1 如果数据量小，可以对数组进行排序，那么数组中间n/2的数就是出现次数超过一半的数,复杂度O(nlogn) 解法2 每次删除数组中两个不同的元素，删除后，要查找的那个元素的个数仍然超过删除后的元素总数的一半 需要两个辅助参数，一个是出现的数值，一个是该数值出现的次数 123456789101112131415161718192021template &lt;typename T&gt;void FindOneNumber(T a[],int size)&#123; if( size &lt;= 0) return -1; int nTimes = 1; int pre = a[0]; for(int i=1;i&lt;size;i++)&#123; if (pre == a[i])&#123; nTimes++; &#125;else&#123; if(nTimes==0)&#123; pre = a[i]; nTimes=1; &#125;else&#123; nTimes--; &#125; &#125; &#125; return pre;&#125; 3.将数值向右移动K个位置(非负数)解法1 每次遍历数组，可以向后移动一位，移动k个位置，则需要k次遍历，O(k*n)123456789101112void move_k(int a[],int size,int k)&#123; // 求需要移动的最小步数， int loca = size%k; for(int i=0;i&lt;loca;i++)&#123; int tmp = a[size-1]; for(int j=size-1;j&gt;=1;j--)&#123; a[j] = a[j-1]; &#125; a[0] = tmp; &#125;&#125;# 时间复杂度 O(k*n) size/k 解法2 借助O(n)的空间，将数组复制到新数组中，然后遍历重新赋值即可，时间O(n)string 形参，可以使用引用const string&amp; str，减少内存的拷贝 12345678910void move_k(int a[],int size,int k)&#123; int loca = size%k; int tmp[size]; # C风格的数组复制方法(memset etc.) memcpy(tmp,a,size*sizeof(int)); for(int i=0;i&lt;size;i++)&#123; a[(i+loca)%size] = tmp[i]; &#125;&#125; 4.判断重复数字 长度为n的数组，赋值为1~n，判断是否存在重复元素 这个数组的特性是，1~n每个值都使用一次才会不重复，所以我们可以将数组对应位置设置为对应的值，去判断是否为冲突 1234567891011121314151617//遍历数组，假设第i个位置的数字为j，则通过交换将j换到下标为j的位置上，直到所有数字都出现在自己对应的下表处，或发生了冲突。//时间复杂度：O(n)，空间复杂度：O(1)bool find_dup(int a[],int size)&#123; if(size&lt;=1) return false; for(int i=0;i&lt;size;i++)&#123; int index = a[i]; if(index-1== i) continue; // 交换前index位置处已经存在index值，这个数字重复 if(a[index-1]==index)&#123; return false; &#125; a[i] = a[index-1]; a[index-1] = index; &#125;&#125; 变形2 普通的数组，则可以通过排序，然后判断前后元素是否相同来确定是否有重复元素 或者利用STL库的set容器，它保存有序的无重复的数组，支持插入，删除，查找等操作，所有的操作的都是严格在logn时间之内完成，效率非常高 1return nums.size() &gt; set&lt;int&gt;(nums.begin(),nums.end()).size(); 5.找出只出现一次的元素 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。(线性复杂度) 解法1 因为其它元素都出现两次，只有一个出现一次，就可以将数组先排序，然后以步长2遍历一次数组，找到 a[i] != a[i+1] 的即可 解法2 可以使用异或运算进行判定，由于都是出现偶数次，而0⊕0=0,1⊕0=1,0⊕1=1,1⊕1=0,且异或满足交换律，所以可以对整个数组进行异或运算，最后得到的结果即为单次出现的数字 12int arr[5] = &#123;4,2,1,2,4&#125;4⊕2⊕1⊕2⊕4 = 4⊕4⊕2⊕2⊕1 = (0)⊕(0)⊕1 = 1 实现 1234567int find_dup2(int a[],int size)&#123; int temp = 0; for(int i=0;i&lt;size;i++)&#123; temp = temp^a[i]; &#125; return temp;&#125; 6.求数组的交集 给定两个数组，编写一个函数来计算它们的交集。 12345输入: nums1 = [4,9,5], nums2 = [9,4,9,8,4]输出: [4,9]输入: nums1 = [1,2,2,1], nums2 = [2,2]输出: [2,2] 说明： 输出结果中每个元素出现的次数，应与元素在两个数组中出现的次数一致。 我们可以不考虑输出结果的顺序。 进阶: 如果给定的数组已经排好序呢？你将如何优化你的算法？ 如果 nums1 的大小比 nums2 小很多，哪种方法更优？ 如果 nums2 的元素存储在磁盘上，磁盘内存是有限的，并且你不能一次加载所有的元素到内存中，你该怎么办？ 解法112345678910111213# 最暴力的方法，时间O(n^2) void find_jiao(int a[],int b[],int size_a,int size_b)&#123; vector&lt;int&gt; c; for(int i=0;i&lt;size_a;i++)&#123; int tmp = a[i]; for(int j=0;j&lt;size_b;j++)&#123; if(tmp == b[j])&#123; c.push_back(tmp); b[j] = -1; break; //找到一样的则跳出，比对第一层遍历数组中的下一个数值 &#125;&#125;&#125;&#125; 排序数组，找交集 如果两个数组是有序的，则可以分别设置一个索引，如果a[index1]&lt;b[index2],则a索引+1，反之亦然，如果两者相等，则存储当前值，并且两个索引都+1 12345678910111213141516171819202122vector&lt;int&gt; find_jiao(int a[],int b[],int size_a,int size_b)&#123; int index1 = 0,index2 = 0; vector&lt;int&gt; c; shell_sort(a,size_a); shell_sort(b,size_b); while(index1&lt;size_a &amp;&amp; index2&lt;size_b)&#123; if(a[index1] &lt; b[index2])&#123; index1++; &#125; else if(a[index1] &gt; b[index2])&#123; index2++; &#125; else&#123; c.push_back(a[index1]); index1++; index2++; &#125; &#125; return c;&#125; 7. Plus One 加1 给定一个由整数组成的非空数组所表示的非负整数，在该数的基础上加一。最高位数字存放在数组的首位， 数组中每个元素只存储一个数字,你可以假设除了整数 0 之外，这个整数不会以零开头。 123输入: [4,3,2,1]输出: [4,3,2,2]解释: 输入数组表示数字 4321。 实现123456789101112void plus_one(int a[],int size)&#123; for(int i=size-1;i&gt;=0;i--)&#123; if(a[i]&lt;9 )&#123; a[i]+=1; break; &#125;else&#123; a[i]=0; i++; &#125; &#125;&#125; 8. 移动所有的0到末尾 使用一个索引标志，遍历一次数组，遍历的同时将非0的元素交换到标志索引处，最后将剩余位置填充0即可！ 123456789101112void move_zero(int a[],int size)&#123; int i=0; for(int x=0;x&lt;size;x++)&#123; if(a[x]!=0) &#123; a[i] = a[x]; i++; &#125; &#125; for(;i&lt;size;i++)&#123; a[i]=0; &#125;&#125; 9.反转字符串 输入: “A man, a plan, a canal: Panama”输出: “amanaP :lanac a ,nalp a ,nam A” 123456789101112void reverseString(string&amp; str)&#123; int i=0,j=str.size()-1; while(i&lt;j)&#123;// swap(str[i++],str[j--]); char s = str[i]; str[i] = str[j]; str[j] = s; i++;j--; &#125; printf(&quot;\n str: %s \n&quot;,str.c_str());&#125; 10.字母异位词 利用了字母易位词即为各个字母的数目相同，而顺序不一致。我们从另外一个角度思考，字母一共有多少个？很明显，只有26个（只考虑小写字母）。那么，我们可以为字符串s1和s2分别设置26个计数器，然后判断这对应位置的计数是否相等，如果对应计数完全相等，则为字母易位词 12输入: s = &quot;anagram&quot;, t = &quot;nagaram&quot;输出: true 实现 123456789101112131415161718bool isAnagram(string s, string t) &#123; if( s.size() != t.size()) return false; int cnt1[26],cnt2[26]; memset(cnt1,0,26* sizeof(int)); memset(cnt2,0,26* sizeof(int)); for(int i=0;i&lt;s.size();i++)&#123; cnt1[s[i]-&apos;a&apos;]++; cnt2[s[i]-&apos;a&apos;]++; &#125; for(int i=0;i&lt;26;i++)&#123; if(cnt1[i] != cnt2[i]) return false; &#125; return true;&#125; 11.回文字符串/**11. 回文字符串 **/ bool isPalindrome(const string&amp; s) { int star =0,end = s.size()-1; while(star&gt;end){ if(toupper(s[star] == s[end])) { star++; end--; }else{ return false; } } return true, } 12.查找字符串数组最长前缀1234例：输入: [“flower”,”flow”,”flight”] 输出: “fl” 示例 2:输入: [“dog”,”racecar”,”car”] 输出: “” 解释: 输入不存在公共前缀。 说明:# 所有输入只包含小写字母 a-z 1234567891011121314151617string longestCommonPrefix(vector&lt;string&gt;&amp; strs) &#123; string res; if(strs.empty())&#123; return &quot;&quot;; &#125; for(int i=0;i&lt;strs[0].size();i++)&#123; char c=strs[0][i]; for(int j=1;j&lt;strs.size();j++)&#123; if(i&gt;strs[j].size()-1||c!=strs[j][i])&#123; return res; &#125; &#125; res.push_back(c); &#125; return res; &#125; 13.合并两个有序链表1234将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。例：输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 实现1234567891011121314151617181920212223242526ListNode* Merge_two(ListNode *l,ListNode* r)&#123; if(l-&gt;next==NULL &amp;&amp; r-&gt;next==NULL) return NULL; ListNode dumpy(0); ListNode* tmp=&amp;dumpy; while(l-&gt;next!=NULL &amp;&amp; r-&gt;next!=NULL)&#123; if(l-&gt;val &gt; r-&gt;val)&#123; tmp-&gt;next = r; r = r-&gt;next; &#125;else&#123; tmp-&gt;next = l; l = l-&gt;next; &#125; tmp = tmp-&gt;next; &#125; if(l!=NULL)&#123; tmp-&gt;next=l; &#125; if(r!=NULL)&#123; tmp-&gt;next=r; &#125; return tmp.next;&#125; 14.合并有序数组 给定两个有序整数数组 nums1 和 nums2，将 nums2 合并到 nums1 中，使得 num1 成为一个有序数组。 初始化 nums1 和 nums2 的元素数量分别为 m 和 n。你可以假设 nums1 有足够的空间（空间大小大于或等于 m + n）来保存 nums2 中的元素。 1234输入:nums1 = [1,2,3,0,0,0], m = 3nums2 = [2,5,6], n = 3输出: [1,2,2,3,5,6] 实现 12 15.数组最大子序和123输入: &#123;1, -2, 3, 10, -4, 7, 2, -5&#125;,输出: 18解释: 最大的子数组为｛3, 10, -4, 7, 2&#125;，和为18 解法1123456789101112# O(n^2) 遍历数组的每一个子序列，记录最大值void maxSubArray(int a[],int size) &#123; int sumMax = 0; for(int l=0;l&lt;size;l++)&#123; int tmp = a[l]; for(int r=0;r&lt;size;r++) &#123; tmp+= a[r]; sumMax = sumMax&gt;tmp?sumMax:tmp; &#125; &#125;&#125; 解法2 我们试着从头到尾逐个累加示例数组中的每个数字。初始化和为 0。第一步加上第一个数字 1， 此时和为 1。接下来第二步加上数字 -2，和就变成了 -1。第三步刷上数字3。我们注意到由于此前累计的和是 －1 ，小于 0，那如果用-1 加上 3 ，得到的和是 2 ， 比 3 本身还小。也就是说从第一个数字开始的子数组的和会小于从第三个数字开始的子数组的和。因此我们不用考虑从第一个数字开始的子数组，之前累计的和也被抛弃。 我们从第三个数字重新开始累加，此时得到的和是 3。接下来第四步加 10，得到和为 13 。第五步加上 -4， 和为 9。我们发现由于 -4 是一个负数，因此累加 -4 之后得到的和比原来的和还要小。因此我们要把之前得到的和 13 保存下来，它有可能是最大的子数组的和。第六步加上数字 7，9 加 7 的结果是 16，此时和比之前最大的和 13 还要大， 把最大的子数组的和由 13 更新为 16。第七步加上 2，累加得到的和为 18，同时我们也要更新最大子数组的和。第八步加上最后一个数字 -5，由于得到的和为 13 ，小于此前最大的和 18，因此最终最大的子数组的和为 18 ，对应的子数组是｛3, 10, -4, 7, 2｝。 根据数组的规律，去进行逐个累加，废弃对最大和没有作用的子序列 实现 1234567891011void maxSubArray(int a[],int size)&#123; int cur=0; int max=0; for(int i=0; i&lt;size; i+=1)&#123; cur += a[i]; // 如果小于0 则丢弃之前子序列的和 从下个索引处开始重新累加 cur = cur&gt;0?cur:0; // 更新最大的子序列和 max = max&gt;cur?max:cur; &#125;&#125; 变形： 何时买卖股票 给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。如果你最多只允许完成一笔交易（即买入和卖出一支股票），设计一个算法来计算你所能获取的最大利润。注意你不能在买入股票前卖出股票 12345输入: [7,1,5,3,6,4]输出: 5解释: 在第2天(股票价格 = 1)的时候买入，在第5天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5,注意利润不能是7-1 =6;输入：[7,6,4,3,1] 这种情况输出0 分析: 其实这个和上面的最大序列和一样，我们可以将价格序列相减，可以得到[0,-6,4,-2,3,-2],然后我们从这个序列中找最大子序列和即可，[4,-2,3]=5即为最大收益 12345678910111213141516171819202122232425# Time O(n) Space O(n)void MaxProfit(int a[],int size)&#123; int buff[size-1]; # 存储收益差 for(int i=0;i&lt;size-1;i++)&#123; buff[i] = a[i+1] - a[i]; &#125; int cur=0; int max=0; for(int i=0;i&lt;size-1;i++)&#123; cur += buff[i]; cur = cur&gt;0?cur:0; max = max&gt;cur?max:cur; &#125;&#125;# 或者不另外开辟空间存储收益差也可以，改动如下： Space o(1) for(int i=1;i&lt;size;i++)&#123; if (cur &lt;= 0)&#123; cur = 0; &#125; cur += a[i]-a[i-1];; max = max&gt;cur?max:cur; &#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分离式编译]]></title>
    <url>%2F2019%2F03%2F11%2F%E5%88%86%E7%A6%BB%E5%BC%8F%E7%BC%96%E8%AF%91%2F</url>
    <content type="text"><![CDATA[C++ 分离式编译模式 是c/c++组织源代码和生成可执行文件的方式，不如同时处理所有.c文件的“全程序编译链接”先进，但是对于内存较小的机器很友好！复杂的源程序需要海量的内存才可以完成全连接编译优化！ 源于C语言，分离式编译：一个项目由若干个源文件共同实现，而每个源文件单独编译生成目标文件(obj),最后将所有的目标文件连接起来形成单一的可执行文件的过程！ 各个cpp文件完全分开编译，然后生成各自的obj目标文件，最后通过连接器link生成一个可执行的exe文件 预处理(Preprocessing) (-E) 编译(Compilation) (-S) 汇编(Assembly) (-c) 连接(Linking) (-o) 参数 含义 -E Preprocess only; do not compile, assemble or link. -S Compile only; do not assemble or link. -c Compile and assemble, but do not link. -o Place the output into . -pie Create a position independent executable. -shared Create a shared library. -x -Wl, Pass comma-separated on to the linker.在生成动态链接库的时候可以传递给链接器参数生成导入库 ldd：可以查看可执行文件 依赖的共享库 分离编译模式的的要点 每个函数或外部变量（全局变量）只能被定义一次，但可以被多次“声明” 123456789using namespace std;void func();void func();void func()&#123; cout&lt;&lt;”This ia a demo”&lt;&lt;endl;&#125;int main()&#123; func();&#125; 函数声明也是有作用域的 一个函数被声明却从未定义，只要没有发生函数调用，编译连接是不会出错的。 12345678910111213141516 #include &lt;iostream&gt;using namespace std;class Demo&#123;public: void func1(); void func2();&#125;;void Demo::func1()&#123; cout&lt;&lt;”This is a demo”&lt;&lt;endl;&#125;int main()&#123; Demo obj;obj.func1();&#125; # 从分离角度来看，func2没有定义，但是因为没有调用func2，所以编译连接时不会寻找具体的函数实现(定义)，从分离编译角度来看，func2有可能在别的源文件实现； 关键是：在分离式编译的环境下，编译器编译某一个.cpp文件时并不知道另一个.cpp文件的存在，也不会去查找[当遇到未决符号时它会寄希望于连接器]。 ###模板不能分离式编译 对于模板(指导编译器生成代码的指令)，模板函数的代码并不能直接编译成二进制代码，其中需要一个实例化过程；既，并不是把模板编译成一个可以处理任何类型的实体，而是对于每一个模板实例，模板都会产生一个不同的实体； 1234567891011121314151617181920212223//-------------test.h-------------------// template&lt;typename T&gt; class A &#123; public: void f();//这里只是个声明 &#125;;//-------------test.cpp-----------------// #include”test.h” template&lt;typename T&gt; voidA::f() //模板的实现，但注意：不是具现 &#123; //dosomething &#125;//---------------main.cpp---------------// #include”test.h” int main() &#123; A a; a.f(); &#125; 在编译main.cpp时，文件中只有f函数的声明，只能寄希望于链接器可以在链接的时候找到其实现，但是在链接时，链接器可以在test.cpp找到f函数的实现？显然是不能的 由于是分离式编译，在编译test.cpp时，没有使用到f函数，所以没有实例化，没有实例化，也就没有在.o文件中生成函数的具体实现 但遇到模板时就傻眼了，因为模板仅在需要的时候才会具现化出来，所以，当编译器只看到模板的声明时，它不能具现化该模板，只能创建一个具有外部连接的符号并期待连接器能够将符号的地址决议出来。所以一般的操作也就是将模板的实现一起写在头文件.h中。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模板类 函数]]></title>
    <url>%2F2019%2F03%2F11%2F%E6%A8%A1%E6%9D%BF%E7%B1%BB-%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[泛型编程既以一种独立于任何特定类型的方式编写代码，可以实现算法和数据结构的分离;简单来说就是代码不局限于类型，模板就是泛型编程的基础。 模板函数 在 C++ 中，模板分为函数模板和类模板两种。函数模板是用于生成函数的，类模板则是用于生成类的。 在模板参数列表中，typename 和 class 关键词含义相同，可互换使用、同时使用，因为typename是在模板广泛使用之后才引入的，所以很多旧程序在使用class 1234567891011121314# 语法template &lt;typename param1,class param2&gt;ret-type func-name(parameter list)&#123; 函数体；&#125;template &lt;class T&gt;void Swap(T &amp;x, T &amp;y, int size)&#123; # size 非模板变量，直接写在形参表中 T tmp = x; x = y; y = tmp;&#125; 其中T为 (形参)类型参数，既 （形参类型 + 形参名字） 编译器在生成具体函数时，会用具体的类型(int\doubule)对模板中的类型参数(T)进行替换，其他部分则原封不动地保留。 模板实例化(显式/隐式) 编译器由模板自动生成函数的过程称为实例化,由模板实例化而得到的函数称为模板函数 模板实例化时还可以显示指定需要实例化的类型模板函数名&lt;类型1,类型2, ...&gt; 如 Swap&lt;int&gt;(2) 一个程序里面同时出现函数模板和普通函数，并且函数名相同 是正确的,并且普通函数的优先级比函数模板的优先级高， 函数模板是编译时自动生 成各种类型的函数实例，如同内联函数，编译时其实现必须可见，一般其实现应该包含在头文件中。 模板函数的声明定义要放在头文件中，不可以分开放在.h和.cpp中。 同样，在一个类中将一个成员函数定义为函数模板时也是要遵从这个规则：实现要放在头文件里。 类模板123456789template &lt;class type&gt; class class-name &#123; // 主体&#125;template &lt;class type&gt;void class-name&lt;type&gt;::func (type a) &#123; // 函数主体&#125; 实例 1234567891011121314151617181920template &lt;class T&gt;class Stack &#123; private: vector&lt;T&gt; elems; // 元素 public: void push(T const&amp;); // 入栈 void pop(); // 出栈 T top() const; // 返回栈顶元素 bool empty() const&#123; // 如果为空则返回真。 return elems.empty(); &#125; &#125;;template &lt;class T&gt;void Stack&lt;T&gt;::push (T const&amp; elem) &#123; // 追加传入元素的副本 elems.push_back(elem); &#125;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github page + hexo + next + .top]]></title>
    <url>%2F2019%2F03%2F11%2Fgithub-page-hexo-next-top%2F</url>
    <content type="text"><![CDATA[github page 创建一个仓库，命名方式为 账号 + .github.io ，例如我的仓库名为：junqiangwu.github.io Hexo - MAC os 安装git 安装node.js 安装hexo node.js直接从官网下载dmg客户端安装node.js官网下载 安装完成以后，使用node -v 和 npm -v 查看版本号，确定安装正确 如果找不到命令node: command not found，则需要在系统环境变量中添加 包的路径MAC的环境变量类似于Linux(左边的先加载):/etc/profile /etc/paths ~/.bash_profile ~/.bash_login ~/.profile ~/.bashrc 打开profile文件，在其中添加1234#默认安装路径在 /usr/local/bin/nodeexport NODE_HOME=&quot;/usr/local&quot; export PATH=$PATH:$NODE_HOME/bin hexo直接命令行安装即可： sudo npm install -g hexo-cli 使用hexo创建本地仓库：12345678# 创建一个blog文件夹mkdir blog# 进入目录cd blog# 初始化目录hexo init# 开启本地服务 # hexo s 即可在localhost:4000 打开hello页面 绑定github page 打开Blog目录，打开站点配置文件 _config.yml ,在deploy添加自己的git仓库地址： 1234# 产生静态网页,每次添加文章之后，都需要这个命令生成静态网页hexo g# 部署到GitHub page上，类似于git pushhexo d 这样就可以通过 name+github.io 地址访问到你的github page Theme Hexo官网：https://hexo.io/themes/里面有特别多的主题可以选择，我在这里选的是next这个主题,效果图 首先clone 下来hexo主题，放到Blog/theme文件里 修改站点配置文件 _config.yml 将里面76行的theme由landscape修改为next 更换新的主题，可能会有一些延迟， 然后就可以通过theme-next的配置文件_config.yml对主题样式进行修改、配置 1234# 新建 分类 和 标签 页面cd ~/bloghexo new page categorieshexo new page tags 具体的主题修改优化配置，可见这个博客，写的很详细：https://zealot.top/设计了头像、背景、评论、缩放等一系列操作 绑定top域名 在仓库里添加CNAME文件 申请一个域名，域名解析 github配置 在仓库里添加一个文件，命名为 CNAME，文件名大写且没有后缀；文件里填写要绑定的域名且不要包含Http://和www 如junqw.top 进入github博客仓库设置(setting)，找到 Custom domain添加域名(junqw.top)后保存即可 域名配置 阿里云购买的域名，这里以阿里云的操作为例，登陆阿里云，依次进入 控制台-万网-域名 找到已购买的域名点击解析按钮，添加两项解析，没试过写ip地址那个，但是这两个解析实测可用 第一项是为了绑定www,注意添加的时候不要忘了最后面的那个&quot;点&quot; 即 junqiangwu.github.io. 这就好了，需要等待一段时间，就可以通过top域名访问你的博客了！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>MAC环境配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Installing PycURL on macOS High Sierra]]></title>
    <url>%2F2019%2F03%2F10%2FInstalling%20PycURL%20on%20macOS%20High%20Sierra%2F</url>
    <content type="text"><![CDATA[Installing PycURL on macOS High Sierra 需要向服务器推送较大的文件，发现python端有一个pycurl库很好的集成了curl命令，在速度上比urllib快很多，不过在Mac端安装的时候总是提示不兼容： 最后在这里找到了解决办法：https://cscheng.info/2018/01/26/installing-pycurl-on-macos-high-sierra.html import pycurlTraceback (most recent call last): File ““, line 1, in ImportError: pycurl: libcurl link-time ssl backend (openssl) is different from compile-time ssl backend (none/other) 如果你没有安装openssl，请安装：brew install openssl或者：brew uggrade openssl 设置环境变量：If you need to have this software first in your PATH run:echo &#39;export PATH=&quot;/usr/local/opt/openssl/bin:$PATH&quot;&#39; &gt;&gt; ~/.bash_profile 卸载之前安装的pycurlpip3 uninstall pycurl 重新安装：1sudo pip3 install --install-option=&quot;--with-openssl&quot; --install-option=&quot;--openssl-dir=/usr/local/opt/openssl&quot; pycurl]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>MAC环境配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TF_Object_Detection API 训练自己模型]]></title>
    <url>%2F2019%2F03%2F10%2FTF-Object-Detection-API-%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[安装Tensorflow_Object_detection_API 依赖库 1Protobuf 、Python-tk、Pillow 1.0、lxml、tf Slim、Jupyter notebook、Matplotlib、Tensorflow、Cython、cocoapi 具体请参考： https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md 安装依赖库：(具体可参考官方文档) 下载源码： 12345678910111213git clone https://github.com/tensorflow/modelssudo apt-get install protobuf-compiler python-pil python-lxml python-tksudo pip3 install Cythonsudo pip3 install jupytersudo pip3 install matplotlib#或者使用pip安装：sudo pip install Cythonsudo pip install pillowsudo pip install lxmlsudo pip install jupytersudo pip install matplotlib 如果使用COCO作为评价指标的话，需要接入coco的pythonApi， 1234git clone https://github.com/cocodataset/cocoapi.gitcd cocoapi/PythonAPImakecp -r pycocotools &lt;path_to_tensorflow&gt;/models/research/ 编译项目From tensorflow/models/research/ 首先protoc编译项目，然后添加环境变量 Mac端： ~./bash_profile 1234567protoc object_detection/protos/*.proto --python_out=.export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim# 如果protoc版本过低，请对应环境下载 https://link.zhihu.com/?target=https%3A//github.com/google/protobuf/releasessudo cp bin/protoc /usr/bin/protoc 再次尝试编译、添加环境 测试安装Ok： python3 object_detection/builders/model_builder_test.py 如果返回Ok 则安装成功，运行setuppython3 setup.py install 制作自己的数据集 并使用API传输训练利用labelImag标注数据，生成xml信息，利用Xml-to-csv.py转换成voc的格式，xml-to-csv脚本： 注意按照自己的文件结构对应修改，我的结构： 123456789101112-train_data/ --...-images/ --test/ ---testingimages.jpg ---image.xml --train/ ---testingimages.jpg ---image.xml --..yourimages.jpg-xml_to_csv.py 1234567891011121314151617181920212223242526272829303132333435import osimport globimport pandas as pdimport xml.etree.ElementTree as ETdef xml_to_csv(path): xml_list = [] for xml_file in glob.glob(path + &apos;/*.xml&apos;): tree = ET.parse(xml_file) root = tree.getroot() for member in root.findall(&apos;object&apos;): value = (root.find(&apos;filename&apos;).text, int(root.find(&apos;size&apos;)[0].text), int(root.find(&apos;size&apos;)[1].text), member[0].text, int(member[4][0].text), int(member[4][1].text), int(member[4][2].text), int(member[4][3].text) ) xml_list.append(value) column_name = [&apos;filename&apos;, &apos;width&apos;, &apos;height&apos;, &apos;class&apos;, &apos;xmin&apos;, &apos;ymin&apos;, &apos;xmax&apos;, &apos;ymax&apos;] xml_df = pd.DataFrame(xml_list, columns=column_name) return xml_dfdef main(): for directory in [&apos;train&apos;,&apos;test&apos;]: image_path = os.path.join(os.getcwd(), &apos;images/&#123;&#125;&apos;.format(directory)) xml_df = xml_to_csv(image_path) xml_df.to_csv(&apos;train_data/&#123;&#125;_labels.csv&apos;.format(directory), index=None) print(&apos;Successfully converted xml to csv.&apos;)main() 将Csv格式的图片信息转换为tf_record格式，提供API训练 首先将上述的images、data移到model/research/object_detedtion文件夹下：利用generate_tfrecord.py转换格式 需要修改 返回的类别和名称 以及文件路径名 https://github.com/junqiangwu/My_Tensorflow/blob/master/object-detection/generate_tfrecord.py From model/research/object_detection/ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798from __future__ import division from __future__ import print_function from __future__ import absolute_import import os import io import pandas as pd import tensorflow as tf from PIL import Image from object_detection.utils import dataset_util from collections import namedtuple, OrderedDict flags = tf.app.flags flags.DEFINE_string(&apos;csv_input&apos;, &apos;&apos;, &apos;Path to the CSV input&apos;) flags.DEFINE_string(&apos;output_path&apos;, &apos;&apos;, &apos;Path to output TFRecord&apos;) FLAGS = flags.FLAGS # TO-DO replace this with label map def class_text_to_int(row_label): if row_label == &apos;macncheese&apos;: return 1 else: None def split(df, group): data = namedtuple(&apos;data&apos;, [&apos;filename&apos;, &apos;object&apos;]) gb = df.groupby(group) return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)] def create_tf_example(group, path): with tf.gfile.GFile(os.path.join(path, &apos;&#123;&#125;&apos;.format(group.filename)), &apos;rb&apos;) as fid: encoded_jpg = fid.read() encoded_jpg_io = io.BytesIO(encoded_jpg) image = Image.open(encoded_jpg_io) width, height = image.size filename = group.filename.encode(&apos;utf8&apos;) image_format = b&apos;jpg&apos; xmins = [] xmaxs = [] ymins = [] ymaxs = [] classes_text = [] classes = [] for index, row in group.object.iterrows(): xmins.append(row[&apos;xmin&apos;] / width) xmaxs.append(row[&apos;xmax&apos;] / width) ymins.append(row[&apos;ymin&apos;] / height) ymaxs.append(row[&apos;ymax&apos;] / height) classes_text.append(row[&apos;class&apos;].encode(&apos;utf8&apos;)) classes.append(class_text_to_int(row[&apos;class&apos;])) tf_example = tf.train.Example(features=tf.train.Features(feature=&#123; &apos;image/height&apos;: dataset_util.int64_feature(height), &apos;image/width&apos;: dataset_util.int64_feature(width), &apos;image/filename&apos;: dataset_util.bytes_feature(filename), &apos;image/source_id&apos;: dataset_util.bytes_feature(filename), &apos;image/encoded&apos;: dataset_util.bytes_feature(encoded_jpg), &apos;image/format&apos;: dataset_util.bytes_feature(image_format), &apos;image/object/bbox/xmin&apos;: dataset_util.float_list_feature(xmins), &apos;image/object/bbox/xmax&apos;: dataset_util.float_list_feature(xmaxs), &apos;image/object/bbox/ymin&apos;: dataset_util.float_list_feature(ymins), &apos;image/object/bbox/ymax&apos;: dataset_util.float_list_feature(ymaxs), &apos;image/object/class/text&apos;: dataset_util.bytes_list_feature(classes_text), &apos;image/object/class/label&apos;: dataset_util.int64_list_feature(classes), &#125;)) return tf_example def main(_): writer = tf.python_io.TFRecordWriter(FLAGS.output_path) path = os.path.join(os.getcwd(), &apos;images&apos;) examples = pd.read_csv(FLAGS.csv_input) grouped = split(examples, &apos;filename&apos;) num=0 for group in grouped: num+=1 tf_example = create_tf_example(group, path) writer.write(tf_example.SerializeToString()) if(num%100==0): #每完成100个转换，打印一次 print(num) writer.close() output_path = os.path.join(os.getcwd(), FLAGS.output_path) print(&apos;Successfully created the TFRecords: &#123;&#125;&apos;.format(output_path)) if __name__ == &apos;__main__&apos;: tf.app.run() 1234python3 generate_tfrecord.py --csv_input=train_data/train_labels.csv --output_path=train.record python3 generate_tfrecord.py --csv_input=train_data/test_labels.csv --output_path=test.record 会在object_detection目录下生成两个.record文件，将它移到train_data目录下，train_data目录下包含：两个csv 和 两个 .record 在object_detection目录下:123456789101112-images/ --test/ ---testingimages.jpg --train/ ---testingimages.jpg --..yourimages.jpg -train_data --train_labels.csv --test_labels.csv --train.record --test.record 下载预训练模型，配置网络结构信息：12345678wget http://download.tensorflow.org/models/object_detection/ ssd_mobilenet_v1_coco_11_06_2017.tar.gzmkdir training 在training文件夹下编写训练数据标签：object_detection.pbtxt item &#123; id: 1 name: &apos;macncheese&apos; #物品类别 &#125; 从object_detection/samples/config/ssd_mobilenet_v1_pets.config移到training文件下：并作出修改： num_class: 1 batch_size: 24 fine_tune_checkpoint: &quot;ssd_mobilenet_v1_coco_11_06_2017/model.ckpt&quot; 123456train_input_reader: &#123; tf_record_input_reader &#123; input_path: &quot;train_data/train.record&quot; &#125; label_map_path: &quot;training/object-detection.pbtxt&quot; &#125; 最后在object_detection文件夹下：运行命令： 1python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config train_dir: 训练输出文件的路径 pipeline_config: 网络配置文件的路径 测试输出模型的准确性 利用.py 转换 .pb From model/research/object_detection 123456python3 export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssd_mobilenet_v1_pets.config --trained_checkpoint_prefix training/model.ckpt-388 --output_directory mac_n_cheese_inference_graph input_type : 保持一致 pipeline: 网络结构配置图 train_checkpoint: ckpt模型保存路径 既上面训练路径的设置位置 out: 输出文件 ####最后利用jupyter notebook加载pb模型进行测试1234567891011121314#修改object_detection_tutorial.ipynb# What model to download.MODEL_NAME = &apos;mac_n_cheese_inference_graph&apos;#Path to frozen detection graph. This is the actual model that is used for the object detection.PATH_TO_CKPT = MODEL_NAME + &apos;/frozen_inference_graph.pb&apos;# List of the strings that is used to add correct label for each box.PATH_TO_LABELS = os.path.join(&apos;training&apos;, &apos;object-detection.pbtxt&apos;)NUM_CLASSES = 1#删除downloand程序，修改加载测试图片的路径，运行即可 所有的配置文件在： https://github.com/junqiangwu/My_Tensorflow/tree/master/object-detection]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mxnet2Caffe]]></title>
    <url>%2F2019%2F03%2F10%2FMxnet2Caffe%2F</url>
    <content type="text"><![CDATA[Mxnet2Caffe 将mxnet静态图symbol转换为caffe的prototxt文本，支持大部分op，caffe不需要的op则需要自己添加，再转换，否则会构建失败 将json转换为prototxt 利用caffe的python接口构建网络，将mxnet的参数param迁移到caffe网络中 构建caffe不支持的op 对结果进行比对 json_2_protxt json2prototxt.py prototxt_basic.py Read mxnet_json file and converte to prototxt 123456789101112131415161718192021222324252627282930313233// json 格式，只要就是op(操作节点和辅助节点null) name attr(参数列表) inputs(输入列表list) &#123; "op": "Activation", "name": "part_0_stage1_unit1_relu1", "attrs": &#123;"act_type": "relu"&#125;, "inputs": [[14, 0, 0]] &#125;, &#123; "op": "null", "name": "part_0_stage1_unit1_conv1_weight", "attrs": &#123; "kernel": "(3, 3)", "no_bias": "True", "num_filter": "64", "pad": "(1, 1)", "stride": "(1, 1)", "workspace": "256" &#125;, "inputs": [] &#125;, &#123; "op": "Convolution", "name": "part_0_stage1_unit1_conv1", "attrs": &#123; "kernel": "(3, 3)", "no_bias": "True", "num_filter": "64", "pad": "(1, 1)", "stride": "(1, 1)", "workspace": "256" &#125;, "inputs": [[15, 0, 0], [16, 0, 0]] &#125;, 读取json文件，并存储相应信息12345678910111213141516171819202122232425262728293031323334353637with open(args.mx_json) as json_file: jdata = json.load(json_file)with open(args.cf_prototxt, "w") as prototxt_file: for i_node in range(0,len(jdata['nodes'])): #logging.info("i_node[%d],'name' %s" %(i_node,jdata['nodes'][i_node]['name'])) node_i = jdata['nodes'][i_node] # 如果当前节点是辅助节点或输入节点(只转换操作节点) 则跳过 if str(node_i['op']) == 'null' and str(node_i['name']) != 'data': continue ''' logging.info('%d, \top:%s, name:%s -&gt; %s'.%(i_node,node_i['op'].ljust(20), node_i['name'].ljust(30), node_i['name']).ljust(20)) ''' ##node[i]个节点 存在的信息 op name param input info = node_i info['top'] = info['name'] info['bottom'] = [] info['params'] = [] # 遍历当前节点的输入 存储辅助参数 for input_idx_i in node_i['inputs']: # jdata['nodes'][input_idx_i[0]] jdana['nodes'][input_index] input_i = jdata['nodes'][input_idx_i[0]] #存储所有输入节点 if str(input_i['op']) != 'null' or (str(input_i['name']) == 'data'): info['bottom'].append(str(input_i['name'])) if str(input_i['op']) == 'null': info['params'].append(str(input_i['name'])) if not str(input_i['name']).startswith(str(node_i['name'])): logging.info(' use shared weight -&gt; %s'% str(input_i['name'])) info['share'] = True write_node(prototxt_file, info) 写prototxt文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# 转换 Convolution 节点操作def Convolution(txt_file, info): if info['attrs']['no_bias'] == 'True': bias_term = 'false' else: bias_term = 'true' txt_file.write('layer &#123;\n') txt_file.write(' bottom: "%s"\n' % info['bottom'][0]) txt_file.write(' top: "%s"\n' % info['top']) txt_file.write(' name: "%s"\n' % info['top']) txt_file.write(' type: "Convolution"\n') txt_file.write(' convolution_param &#123;\n') txt_file.write(' num_output: %s\n' % info['attrs']['num_filter']) txt_file.write(' kernel_size: %s\n' % info['attrs']['kernel'].split('(')[1].split(',')[0]) # TODO if 'pad' not in info['attrs']: logging.info('miss Conv_pad, make pad default: 0 ') txt_file.write(' pad: %s\n' % 0) # TODO else: txt_file.write(' pad: %s\n' % info['attrs']['pad'].split('(')[1].split(',')[0]) # TODO# txt_file.write(' group: %s\n' % info['attrs']['num_group']) txt_file.write(' stride: %s\n' % info['attrs']['stride'].split('(')[1].split(',')[0]) txt_file.write(' bias_term: %s\n' % bias_term) txt_file.write(' &#125;\n') if 'share' in info.keys() and info['share']: txt_file.write(' param &#123;\n') txt_file.write(' name: "%s"\n' % info['params'][0]) txt_file.write(' &#125;\n') txt_file.write('&#125;\n') txt_file.write('\n')# -------根据op操作，完善相应的转换函数-----------# 目前包含Conv Pool DepthConv BN Act ele_add Concat FC Reshape etc. def write_node(txt_file, info): if 'label' in info['name']: return if info['op'] == 'null' and info['name'] == 'data': data(txt_file, info) elif info['op'] == 'Convolution': Convolution(txt_file, info) elif info['op'] == 'ChannelwiseConvolution': ChannelwiseConvolution(txt_file, info) elif info['op'] == 'BatchNorm': BatchNorm(txt_file, info) elif info['op'] == 'Activation': Activation(txt_file, info)# elif info['op'] == 'ElementWiseSum': elif info['op'] == 'elemwise_add': ElementWiseSum(txt_file, info) elif info['op'] == '_Plus': ElementWiseSum(txt_file, info) elif info['op'] == 'Concat': Concat(txt_file, info) elif info['op'] == 'Pooling':# Pooling(txt_file, info) Pooling_global(txt_file, info) elif info['op'] == 'Flatten': Flatten(txt_file, info) elif info['op'] == 'FullyConnected': FullyConnected(txt_file, info) elif info['op'] == 'SoftmaxOutput': SoftmaxOutput(txt_file, info) elif info['op'] == 'Cast': Cast(txt_file, info) elif info['op'] == 'SliceChannel': SliceChannel(txt_file, info) elif info['op'] == 'L2Normalization': L2Normalization(txt_file, info) elif info['op'] == 'Reshape': Reshape(txt_file,info) elif info['op'] == 'broadcast_mul': broadcast_mul(txt_file,info) else: logging.warn("Unknown mxnet op: %s" %info['op']) 利用caffe的python接口，构建网络，并迁移mxnet的网络参数1.mxnet2caffe.py Read mxnet_model params_dict and converte to .caffemodel 转换的时候如果存在caffe不支持的op，需要自己添加自定义层，否则在构建网络时，会error，本工程添加了broadcast_mul层caffe添加自定义层的介绍比较多，就跳过了 根据mxnet的API (load) 加载param文件的所有参数字典12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152try: import caffeexcept ImportError: import os, sys sys.path.append("/home/***/codes/mx2caffe/caffe/python/") import caffe#读取全部param 参数字典 _, arg_params, aux_params = mx.model.load_checkpoint(args.mx_model, args.mx_epoch)all_keys = arg_params.keys() + aux_params.keys()# 利用caffe的python接口，读取刚转换的proto构建网络，net = caffe.Net(args.cf_prototxt, caffe.TRAIN)for i_key,key_i in enumerate(all_keys): try: if 'data' is key_i: pass # 在mxnet字典中，存有caffe不需要的后缀，_weight _bias # 需要确认caffe的参数保存顺序 [0]是weight [1]是bias 其它op 类似查看proto结构设计 elif '_weight' in key_i: key_caffe = key_i.replace('_weight','') net.params[key_caffe][0].data.flat = arg_params[key_i].asnumpy().flat elif '_bias' in key_i: key_caffe = key_i.replace('_bias','') net.params[key_caffe][1].data.flat = arg_params[key_i].asnumpy().flat elif '_gamma' in key_i: key_caffe = key_i.replace('_gamma','_scale') net.params[key_caffe][0].data.flat = arg_params[key_i].asnumpy().flat elif '_beta' in key_i: key_caffe = key_i.replace('_beta','_scale') net.params[key_caffe][1].data.flat = arg_params[key_i].asnumpy().flat elif '_moving_mean' in key_i: key_caffe = key_i.replace('_moving_mean','') net.params[key_caffe][0].data.flat = aux_params[key_i].asnumpy().flat net.params[key_caffe][2].data[...] = 1 elif '_moving_var' in key_i: key_caffe = key_i.replace('_moving_var','') net.params[key_caffe][1].data.flat = aux_params[key_i].asnumpy().flat net.params[key_caffe][2].data[...] = 1 else: sys.exit("Warning! Unknown mxnet:&#123;&#125;".format(key_i)) print("% 3d | %s -&gt; %s, initialized." %(i_key, key_i.ljust(40), key_caffe.ljust(30))) except KeyError: print("\nWarning! key error mxnet:&#123;&#125;".format(key_i)) # ------------------------------------------# Finishnet.save(args.cf_model)print("\n- Finished.\n") 对转换结果进行比对确认 mxnet_test.py Debug mxnet output and you can compare the result with the converted caffemodel 使用mxnet debug， 打印需要对比的参数，并且输出指定层的结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import mxnet as mxdef load_checkpoint_single(model, param_path): arg_params = &#123;&#125; aux_params = &#123;&#125; save_dict = mx.nd.load(param_path) for k, value in save_dict.items(): arg_type, name = k.split(':', 1) if arg_type == 'arg': arg_params[name] = value if arg_type == 'aux': aux_params[name] = value else : pass model.set_params(arg_params, aux_params, allow_missing=False) arg_params, aux_params = model.get_params() return arg_params, aux_paramsfull_param_path = 'se_resnet34/base-0000.params'fmodel = mx.sym.load('se_resnet34/base-symbol.json')# 获取mxnet网络的所有layer参数all_layers = fmodel.get_internals()# 修改这里为需要输出layer的name+output即可指定层输出 ‘name_output’fmodel = all_layers['flat_output']fullmodel = mx.mod.Module(symbol=fmodel,data_names=['data'],label_names=[])img = []img = get_image_gray('before_forward.jpg')fullmodel.bind(data_shapes=[('data', (1, 1, 108, 108))], label_shapes=None, for_training=False, force_rebind=False)arg_params, aux_params = load_checkpoint_single(fullmodel, full_param_path)fullmodel.set_params(arg_params,aux_params)file1=open('se_resnet34.txt','w')tic=time.time()fullmodel.forward(Batch([mx.nd.array(img)]))prob = fullmodel.get_outputs()[0].asnumpy()prob = prob.astype(np.float64)prob = prob.reshape(-1,1)# 以特定的格式保存结果np.savetxt(file1,prob,fmt='%.12f')file1.close() 然后利用Caffe 加载刚才转换的网络，打印输出，对比结果精度，如果出现问题，则需要逐层排查，本工程在SENet网络上测试正常 工程项目地址 https://github.com/junqiangwu/Mxnet2Caffe-Tensor-RT-SEnet TODO: add caffe_plugin_layer Tensor RT load caffe_model Tensor RT supported Se_Resnet]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Mxnet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NAS (Neural Architecture Search)]]></title>
    <url>%2F2019%2F03%2F09%2FFBNET%2F</url>
    <content type="text"><![CDATA[NAS(Neural Architecture Search)FBNet Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture SearchImplementation of FBNet with MXNet paper address: https://arxiv.org/pdf/1812.03443.pdf Implemented Net: FBNet FBNet Based on Se_Resnet_50_Architecture other block_type architecture cound be easily implement by modify fbnet-symbol/block.py Code: blocks.py: Define blocks symbols FBNet.py: Define FBNet Class. FBNet_SE.py: Define FBNet Architecture based on Se_resnet_50. blocks_se.py: Define blocks symbols based on new search space,include [Resnet_50,Se,Group_Conv,Channel_shuffle,Deform_Conv] util.py: Define some functions. test.py: Run test. block_speed_test.py: test block lat in real environment(1080Ti) Differences from original paper: The last conv layer’s num_filters is repalced by feature_dim specified by paramters Use Amsoftmax, Arcface instead of FC, but you can set model_type to softamx to use fc Default input shape is 3,108,108, so the first conv layer has stride 1 instead of 2. Add BN out of blocks, and no bn inside blocks. Last conv has kernel size 3,3 Use + in loss not *. Adding gradient rising stage in cosine decaying schedule. Code in fbnet-symbom/util/CosineDecayScheduler_Grad How to train:If you want to modify the network structure or the learning rate adjustment function, you need to modify the source code,otherwise you can use this command directly: 1python test.py --gpu 0,1,2,3,4,5,6 --log-frequence 50 --model-type softmax --batch-size 32 How to retrain:When we want to train the large dataset and hope to change learning rate manually, or the machine is suddenly shutdown due to some reason,of course, we definitely hope we can continue to train model with previous trained weights. Then, your can use this cmd: 1python test.py --gpu 0,1,2,3,4,5,6 --log-frequence 50 --model-type softmax --batch-size 32 --load-model-path ./model This can load the latest model params for retrain,If you want to load the model with specific epoch,you can use –load-model-path ./model/*.params ,This means you can retrain your model from specific model. TODO: sample script, for now just save $\theta$ cosine decaying schedule lat in real environment DataParallel implementation]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
</search>
