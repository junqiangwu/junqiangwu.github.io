<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[算法随笔]]></title>
    <url>%2F2019%2F03%2F11%2F%E7%AE%97%E6%B3%95%E9%9A%8F%E7%AC%94%2F</url>
    <content type="text"><![CDATA[##算法随笔 1.原地删除重复的数字 给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。 12345给定 nums = [0,0,1,1,1,2,2,3,3,4],函数应该返回新的长度 5, 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4。你不需要考虑数组中超出新长度后面的元素。 实现12345678910111213int remove_duplicates(int a[],int size)&#123; int index = 0; for (int i=0;i&lt;size;i++)&#123; // 一直寻找到不重复的元素，进行交换，index+1 if(a[index] != a[i])&#123; index++; a[index] = a[i]; &#125; &#125; index++; return index;&#125; 2.数组中出现次数超过一半的元素 数组(无序)中有一个数字出现的次数超过了数组长度的一半，找出这个数字。 解法1 如果数据量小，可以对数组进行排序，那么数组中间n/2的数就是出现次数超过一半的数,复杂度O(nlogn) 解法2 每次删除数组中两个不同的元素，删除后，要查找的那个元素的个数仍然超过删除后的元素总数的一半 需要两个辅助参数，一个是出现的数值，一个是该数值出现的次数 123456789101112131415161718192021template &lt;typename T&gt;void FindOneNumber(T a[],int size)&#123; if( size &lt;= 0) return -1; int nTimes = 1; int pre = a[0]; for(int i=1;i&lt;size;i++)&#123; if (pre == a[i])&#123; nTimes++; &#125;else&#123; if(nTimes==0)&#123; pre = a[i]; nTimes=1; &#125;else&#123; nTimes--; &#125; &#125; &#125; return pre;&#125; 3.将数值向右移动K个位置(非负数) 123456789101112void move_k(int a[],int size,int k)&#123; // 求需要移动的最小步数， int loca = size%k; for(int i=0;i&lt;loca;i++)&#123; int tmp = a[size-1]; for(int j=size-1;j&gt;=1;j--)&#123; a[j] = a[j-1]; &#125; a[0] = tmp; &#125;&#125;# 时间复杂度 O(k*n) size/k 解法2 借助O(n)的空间，将数组复制到新数组中，然后遍历重新赋值即可，时间O(n)string 形参，可以使用引用const string&amp; str，减少内存的拷贝 12345678910void move_k(int a[],int size,int k)&#123; int loca = size%k; int tmp[size]; # C风格的数组复制方法(memset etc.) memcpy(tmp,a,size*sizeof(int)); for(int i=0;i&lt;size;i++)&#123; a[(i+loca)%size] = tmp[i]; &#125;&#125; 4.判断重复数字 长度为n的数组，赋值为1~n，判断是否存在重复元素 这个数组的特性是，1~n每个值都使用一次才会不重复，所以我们可以将数组对应位置设置为对应的值，去判断是否为冲突 1234567891011121314151617//遍历数组，假设第i个位置的数字为j，则通过交换将j换到下标为j的位置上，直到所有数字都出现在自己对应的下表处，或发生了冲突。//时间复杂度：O(n)，空间复杂度：O(1)bool find_dup(int a[],int size)&#123; if(size&lt;=1) return false; for(int i=0;i&lt;size;i++)&#123; int index = a[i]; if(index-1== i) continue; // 交换前index位置处已经存在index值，这个数字重复 if(a[index-1]==index)&#123; return false; &#125; a[i] = a[index-1]; a[index-1] = index; &#125;&#125; 变形2 普通的数组，则可以通过排序，然后判断前后元素是否相同来确定是否有重复元素 或者利用STL库的set容器，它保存有序的无重复的数组，支持插入，删除，查找等操作，所有的操作的都是严格在logn时间之内完成，效率非常高 1return nums.size() &gt; set&lt;int&gt;(nums.begin(),nums.end()).size(); 5.找出只出现一次的元素 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。(线性复杂度) 解法1 因为其它元素都出现两次，只有一个出现一次，就可以将数组先排序，然后以步长2遍历一次数组，找到 a[i] != a[i+1] 的即可 解法2 可以使用异或运算进行判定，由于都是出现偶数次，而0⊕0=0,1⊕0=1,0⊕1=1,1⊕1=0,且异或满足交换律，所以可以对整个数组进行异或运算，最后得到的结果即为单次出现的数字 12int arr[5] = &#123;4,2,1,2,4&#125;4⊕2⊕1⊕2⊕4 = 4⊕4⊕2⊕2⊕1 = (0)⊕(0)⊕1 = 1 实现 1234567int find_dup2(int a[],int size)&#123; int temp = 0; for(int i=0;i&lt;size;i++)&#123; temp = temp^a[i]; &#125; return temp;&#125; 6.求数组的交集 给定两个数组，编写一个函数来计算它们的交集。 12345输入: nums1 = [4,9,5], nums2 = [9,4,9,8,4]输出: [4,9]输入: nums1 = [1,2,2,1], nums2 = [2,2]输出: [2,2] 说明： 输出结果中每个元素出现的次数，应与元素在两个数组中出现的次数一致。 我们可以不考虑输出结果的顺序。 进阶: 如果给定的数组已经排好序呢？你将如何优化你的算法？ 如果 nums1 的大小比 nums2 小很多，哪种方法更优？ 如果 nums2 的元素存储在磁盘上，磁盘内存是有限的，并且你不能一次加载所有的元素到内存中，你该怎么办？]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分离式编译]]></title>
    <url>%2F2019%2F03%2F11%2F%E5%88%86%E7%A6%BB%E5%BC%8F%E7%BC%96%E8%AF%91%2F</url>
    <content type="text"><![CDATA[C++ 分离式编译模式 是c/c++组织源代码和生成可执行文件的方式，不如同时处理所有.c文件的“全程序编译链接”先进，但是对于内存较小的机器很友好！复杂的源程序需要海量的内存才可以完成全连接编译优化！ 源于C语言，分离式编译：一个项目由若干个源文件共同实现，而每个源文件单独编译生成目标文件(obj),最后将所有的目标文件连接起来形成单一的可执行文件的过程！ 各个cpp文件完全分开编译，然后生成各自的obj目标文件，最后通过连接器link生成一个可执行的exe文件 预处理(Preprocessing) (-E) 编译(Compilation) (-S) 汇编(Assembly) (-c) 连接(Linking) (-o) 参数 含义 -E Preprocess only; do not compile, assemble or link. -S Compile only; do not assemble or link. -c Compile and assemble, but do not link. -o Place the output into . -pie Create a position independent executable. -shared Create a shared library. -x -Wl, Pass comma-separated on to the linker.在生成动态链接库的时候可以传递给链接器参数生成导入库 ldd：可以查看可执行文件 依赖的共享库 分离编译模式的的要点 每个函数或外部变量（全局变量）只能被定义一次，但可以被多次“声明” 123456789using namespace std;void func();void func();void func()&#123; cout&lt;&lt;”This ia a demo”&lt;&lt;endl;&#125;int main()&#123; func();&#125; 函数声明也是有作用域的 一个函数被声明却从未定义，只要没有发生函数调用，编译连接是不会出错的。 12345678910111213141516 #include &lt;iostream&gt;using namespace std;class Demo&#123;public: void func1(); void func2();&#125;;void Demo::func1()&#123; cout&lt;&lt;”This is a demo”&lt;&lt;endl;&#125;int main()&#123; Demo obj;obj.func1();&#125; # 从分离角度来看，func2没有定义，但是因为没有调用func2，所以编译连接时不会寻找具体的函数实现(定义)，从分离编译角度来看，func2有可能在别的源文件实现； 关键是：在分离式编译的环境下，编译器编译某一个.cpp文件时并不知道另一个.cpp文件的存在，也不会去查找[当遇到未决符号时它会寄希望于连接器]。 ###模板不能分离式编译 对于模板(指导编译器生成代码的指令)，模板函数的代码并不能直接编译成二进制代码，其中需要一个实例化过程；既，并不是把模板编译成一个可以处理任何类型的实体，而是对于每一个模板实例，模板都会产生一个不同的实体； 1234567891011121314151617181920212223//-------------test.h-------------------// template&lt;typename T&gt; class A &#123; public: void f();//这里只是个声明 &#125;;//-------------test.cpp-----------------// #include”test.h” template&lt;typename T&gt; voidA::f() //模板的实现，但注意：不是具现 &#123; //dosomething &#125;//---------------main.cpp---------------// #include”test.h” int main() &#123; A a; a.f(); &#125; 在编译main.cpp时，文件中只有f函数的声明，只能寄希望于链接器可以在链接的时候找到其实现，但是在链接时，链接器可以在test.cpp找到f函数的实现？显然是不能的 由于是分离式编译，在编译test.cpp时，没有使用到f函数，所以没有实例化，没有实例化，也就没有在.o文件中生成函数的具体实现 但遇到模板时就傻眼了，因为模板仅在需要的时候才会具现化出来，所以，当编译器只看到模板的声明时，它不能具现化该模板，只能创建一个具有外部连接的符号并期待连接器能够将符号的地址决议出来。所以一般的操作也就是将模板的实现一起写在头文件.h中。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模板类 函数]]></title>
    <url>%2F2019%2F03%2F11%2F%E6%A8%A1%E6%9D%BF%E7%B1%BB-%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[泛型编程既以一种独立于任何特定类型的方式编写代码，可以实现算法和数据结构的分离;简单来说就是代码不局限于类型，模板就是泛型编程的基础。 模板函数 在 C++ 中，模板分为函数模板和类模板两种。函数模板是用于生成函数的，类模板则是用于生成类的。 在模板参数列表中，typename 和 class 关键词含义相同，可互换使用、同时使用，因为typename是在模板广泛使用之后才引入的，所以很多旧程序在使用class 1234567891011121314# 语法template &lt;typename param1,class param2&gt;ret-type func-name(parameter list)&#123; 函数体；&#125;template &lt;class T&gt;void Swap(T &amp;x, T &amp;y, int size)&#123; # size 非模板变量，直接写在形参表中 T tmp = x; x = y; y = tmp;&#125; 其中T为 (形参)类型参数，既 （形参类型 + 形参名字） 编译器在生成具体函数时，会用具体的类型(int\doubule)对模板中的类型参数(T)进行替换，其他部分则原封不动地保留。 模板实例化(显式/隐式) 编译器由模板自动生成函数的过程称为实例化,由模板实例化而得到的函数称为模板函数 模板实例化时还可以显示指定需要实例化的类型模板函数名&lt;类型1,类型2, ...&gt; 如 Swap&lt;int&gt;(2) 一个程序里面同时出现函数模板和普通函数，并且函数名相同 是正确的,并且普通函数的优先级比函数模板的优先级高， 函数模板是编译时自动生 成各种类型的函数实例，如同内联函数，编译时其实现必须可见，一般其实现应该包含在头文件中。 模板函数的声明定义要放在头文件中，不可以分开放在.h和.cpp中。 同样，在一个类中将一个成员函数定义为函数模板时也是要遵从这个规则：实现要放在头文件里。 类模板123456789template &lt;class type&gt; class class-name &#123; // 主体&#125;template &lt;class type&gt;void class-name&lt;type&gt;::func (type a) &#123; // 函数主体&#125; 实例 1234567891011121314151617181920template &lt;class T&gt;class Stack &#123; private: vector&lt;T&gt; elems; // 元素 public: void push(T const&amp;); // 入栈 void pop(); // 出栈 T top() const; // 返回栈顶元素 bool empty() const&#123; // 如果为空则返回真。 return elems.empty(); &#125; &#125;;template &lt;class T&gt;void Stack&lt;T&gt;::push (T const&amp; elem) &#123; // 追加传入元素的副本 elems.push_back(elem); &#125;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github page + hexo + next + .top]]></title>
    <url>%2F2019%2F03%2F11%2Fgithub-page-hexo-next-top%2F</url>
    <content type="text"><![CDATA[github page 创建一个仓库，命名方式为 账号 + .github.io ，例如我的仓库名为：junqiangwu.github.io Hexo - MAC os 安装git 安装node.js 安装hexo node.js直接从官网下载dmg客户端安装node.js官网下载 安装完成以后，使用node -v 和 npm -v 查看版本号，确定安装正确 如果找不到命令node: command not found，则需要在系统环境变量中添加 包的路径MAC的环境变量类似于Linux(左边的先加载):/etc/profile /etc/paths ~/.bash_profile ~/.bash_login ~/.profile ~/.bashrc 打开profile文件，在其中添加1234#默认安装路径在 /usr/local/bin/nodeexport NODE_HOME=&quot;/usr/local&quot; export PATH=$PATH:$NODE_HOME/bin hexo直接命令行安装即可： sudo npm install -g hexo-cli 使用hexo创建本地仓库：12345678# 创建一个blog文件夹mkdir blog# 进入目录cd blog# 初始化目录hexo init# 开启本地服务 # hexo s 即可在localhost:4000 打开hello页面 绑定github page 打开Blog目录，打开站点配置文件 _config.yml ,在deploy添加自己的git仓库地址： 1234# 产生静态网页,每次添加文章之后，都需要这个命令生成静态网页hexo g# 部署到GitHub page上，类似于git pushhexo d 这样就可以通过 name+github.io 地址访问到你的github page Theme Hexo官网：https://hexo.io/themes/里面有特别多的主题可以选择，我在这里选的是next这个主题,效果图 首先clone 下来hexo主题，放到Blog/theme文件里 修改站点配置文件 _config.yml 将里面76行的theme由landscape修改为next 更换新的主题，可能会有一些延迟， 然后就可以通过theme-next的配置文件_config.yml对主题样式进行修改、配置 1234# 新建 分类 和 标签 页面cd ~/bloghexo new page categorieshexo new page tags 具体的主题修改优化配置，可见这个博客，写的很详细：https://zealot.top/设计了头像、背景、评论、缩放等一系列操作 绑定top域名 在仓库里添加CNAME文件 申请一个域名，域名解析 github配置 在仓库里添加一个文件，命名为 CNAME，文件名大写且没有后缀；文件里填写要绑定的域名且不要包含Http://和www 如junqw.top 进入github博客仓库设置(setting)，找到 Custom domain添加域名(junqw.top)后保存即可 域名配置 阿里云购买的域名，这里以阿里云的操作为例，登陆阿里云，依次进入 控制台-万网-域名 找到已购买的域名点击解析按钮，添加两项解析，没试过写ip地址那个，但是这两个解析实测可用 第一项是为了绑定www,注意添加的时候不要忘了最后面的那个&quot;点&quot; 即 junqiangwu.github.io. 这就好了，需要等待一段时间，就可以通过top域名访问你的博客了！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>MAC环境配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Installing PycURL on macOS High Sierra]]></title>
    <url>%2F2019%2F03%2F10%2FInstalling%20PycURL%20on%20macOS%20High%20Sierra%2F</url>
    <content type="text"><![CDATA[Installing PycURL on macOS High Sierra 需要向服务器推送较大的文件，发现python端有一个pycurl库很好的集成了curl命令，在速度上比urllib快很多，不过在Mac端安装的时候总是提示不兼容： 最后在这里找到了解决办法：https://cscheng.info/2018/01/26/installing-pycurl-on-macos-high-sierra.html import pycurlTraceback (most recent call last): File ““, line 1, in ImportError: pycurl: libcurl link-time ssl backend (openssl) is different from compile-time ssl backend (none/other) 如果你没有安装openssl，请安装：brew install openssl或者：brew uggrade openssl 设置环境变量：If you need to have this software first in your PATH run:echo &#39;export PATH=&quot;/usr/local/opt/openssl/bin:$PATH&quot;&#39; &gt;&gt; ~/.bash_profile 卸载之前安装的pycurlpip3 uninstall pycurl 重新安装：1sudo pip3 install --install-option=&quot;--with-openssl&quot; --install-option=&quot;--openssl-dir=/usr/local/opt/openssl&quot; pycurl]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>MAC环境配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TF_Object_Detection API 训练自己模型]]></title>
    <url>%2F2019%2F03%2F10%2FTF-Object-Detection-API-%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[安装Tensorflow_Object_detection_API 依赖库 1Protobuf 、Python-tk、Pillow 1.0、lxml、tf Slim、Jupyter notebook、Matplotlib、Tensorflow、Cython、cocoapi 具体请参考： https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md 安装依赖库：(具体可参考官方文档) 下载源码： 12345678910111213git clone https://github.com/tensorflow/modelssudo apt-get install protobuf-compiler python-pil python-lxml python-tksudo pip3 install Cythonsudo pip3 install jupytersudo pip3 install matplotlib#或者使用pip安装：sudo pip install Cythonsudo pip install pillowsudo pip install lxmlsudo pip install jupytersudo pip install matplotlib 如果使用COCO作为评价指标的话，需要接入coco的pythonApi， 1234git clone https://github.com/cocodataset/cocoapi.gitcd cocoapi/PythonAPImakecp -r pycocotools &lt;path_to_tensorflow&gt;/models/research/ 编译项目From tensorflow/models/research/ 首先protoc编译项目，然后添加环境变量 Mac端： ~./bash_profile 1234567protoc object_detection/protos/*.proto --python_out=.export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim# 如果protoc版本过低，请对应环境下载 https://link.zhihu.com/?target=https%3A//github.com/google/protobuf/releasessudo cp bin/protoc /usr/bin/protoc 再次尝试编译、添加环境 测试安装Ok： python3 object_detection/builders/model_builder_test.py 如果返回Ok 则安装成功，运行setuppython3 setup.py install 制作自己的数据集 并使用API传输训练利用labelImag标注数据，生成xml信息，利用Xml-to-csv.py转换成voc的格式，xml-to-csv脚本： 注意按照自己的文件结构对应修改，我的结构： 123456789101112-train_data/ --...-images/ --test/ ---testingimages.jpg ---image.xml --train/ ---testingimages.jpg ---image.xml --..yourimages.jpg-xml_to_csv.py 1234567891011121314151617181920212223242526272829303132333435import osimport globimport pandas as pdimport xml.etree.ElementTree as ETdef xml_to_csv(path): xml_list = [] for xml_file in glob.glob(path + &apos;/*.xml&apos;): tree = ET.parse(xml_file) root = tree.getroot() for member in root.findall(&apos;object&apos;): value = (root.find(&apos;filename&apos;).text, int(root.find(&apos;size&apos;)[0].text), int(root.find(&apos;size&apos;)[1].text), member[0].text, int(member[4][0].text), int(member[4][1].text), int(member[4][2].text), int(member[4][3].text) ) xml_list.append(value) column_name = [&apos;filename&apos;, &apos;width&apos;, &apos;height&apos;, &apos;class&apos;, &apos;xmin&apos;, &apos;ymin&apos;, &apos;xmax&apos;, &apos;ymax&apos;] xml_df = pd.DataFrame(xml_list, columns=column_name) return xml_dfdef main(): for directory in [&apos;train&apos;,&apos;test&apos;]: image_path = os.path.join(os.getcwd(), &apos;images/&#123;&#125;&apos;.format(directory)) xml_df = xml_to_csv(image_path) xml_df.to_csv(&apos;train_data/&#123;&#125;_labels.csv&apos;.format(directory), index=None) print(&apos;Successfully converted xml to csv.&apos;)main() 将Csv格式的图片信息转换为tf_record格式，提供API训练 首先将上述的images、data移到model/research/object_detedtion文件夹下：利用generate_tfrecord.py转换格式 需要修改 返回的类别和名称 以及文件路径名 https://github.com/junqiangwu/My_Tensorflow/blob/master/object-detection/generate_tfrecord.py From model/research/object_detection/ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798from __future__ import division from __future__ import print_function from __future__ import absolute_import import os import io import pandas as pd import tensorflow as tf from PIL import Image from object_detection.utils import dataset_util from collections import namedtuple, OrderedDict flags = tf.app.flags flags.DEFINE_string(&apos;csv_input&apos;, &apos;&apos;, &apos;Path to the CSV input&apos;) flags.DEFINE_string(&apos;output_path&apos;, &apos;&apos;, &apos;Path to output TFRecord&apos;) FLAGS = flags.FLAGS # TO-DO replace this with label map def class_text_to_int(row_label): if row_label == &apos;macncheese&apos;: return 1 else: None def split(df, group): data = namedtuple(&apos;data&apos;, [&apos;filename&apos;, &apos;object&apos;]) gb = df.groupby(group) return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)] def create_tf_example(group, path): with tf.gfile.GFile(os.path.join(path, &apos;&#123;&#125;&apos;.format(group.filename)), &apos;rb&apos;) as fid: encoded_jpg = fid.read() encoded_jpg_io = io.BytesIO(encoded_jpg) image = Image.open(encoded_jpg_io) width, height = image.size filename = group.filename.encode(&apos;utf8&apos;) image_format = b&apos;jpg&apos; xmins = [] xmaxs = [] ymins = [] ymaxs = [] classes_text = [] classes = [] for index, row in group.object.iterrows(): xmins.append(row[&apos;xmin&apos;] / width) xmaxs.append(row[&apos;xmax&apos;] / width) ymins.append(row[&apos;ymin&apos;] / height) ymaxs.append(row[&apos;ymax&apos;] / height) classes_text.append(row[&apos;class&apos;].encode(&apos;utf8&apos;)) classes.append(class_text_to_int(row[&apos;class&apos;])) tf_example = tf.train.Example(features=tf.train.Features(feature=&#123; &apos;image/height&apos;: dataset_util.int64_feature(height), &apos;image/width&apos;: dataset_util.int64_feature(width), &apos;image/filename&apos;: dataset_util.bytes_feature(filename), &apos;image/source_id&apos;: dataset_util.bytes_feature(filename), &apos;image/encoded&apos;: dataset_util.bytes_feature(encoded_jpg), &apos;image/format&apos;: dataset_util.bytes_feature(image_format), &apos;image/object/bbox/xmin&apos;: dataset_util.float_list_feature(xmins), &apos;image/object/bbox/xmax&apos;: dataset_util.float_list_feature(xmaxs), &apos;image/object/bbox/ymin&apos;: dataset_util.float_list_feature(ymins), &apos;image/object/bbox/ymax&apos;: dataset_util.float_list_feature(ymaxs), &apos;image/object/class/text&apos;: dataset_util.bytes_list_feature(classes_text), &apos;image/object/class/label&apos;: dataset_util.int64_list_feature(classes), &#125;)) return tf_example def main(_): writer = tf.python_io.TFRecordWriter(FLAGS.output_path) path = os.path.join(os.getcwd(), &apos;images&apos;) examples = pd.read_csv(FLAGS.csv_input) grouped = split(examples, &apos;filename&apos;) num=0 for group in grouped: num+=1 tf_example = create_tf_example(group, path) writer.write(tf_example.SerializeToString()) if(num%100==0): #每完成100个转换，打印一次 print(num) writer.close() output_path = os.path.join(os.getcwd(), FLAGS.output_path) print(&apos;Successfully created the TFRecords: &#123;&#125;&apos;.format(output_path)) if __name__ == &apos;__main__&apos;: tf.app.run() 1234python3 generate_tfrecord.py --csv_input=train_data/train_labels.csv --output_path=train.record python3 generate_tfrecord.py --csv_input=train_data/test_labels.csv --output_path=test.record 会在object_detection目录下生成两个.record文件，将它移到train_data目录下，train_data目录下包含：两个csv 和 两个 .record 在object_detection目录下:123456789101112-images/ --test/ ---testingimages.jpg --train/ ---testingimages.jpg --..yourimages.jpg -train_data --train_labels.csv --test_labels.csv --train.record --test.record 下载预训练模型，配置网络结构信息：12345678wget http://download.tensorflow.org/models/object_detection/ ssd_mobilenet_v1_coco_11_06_2017.tar.gzmkdir training 在training文件夹下编写训练数据标签：object_detection.pbtxt item &#123; id: 1 name: &apos;macncheese&apos; #物品类别 &#125; 从object_detection/samples/config/ssd_mobilenet_v1_pets.config移到training文件下：并作出修改： num_class: 1 batch_size: 24 fine_tune_checkpoint: &quot;ssd_mobilenet_v1_coco_11_06_2017/model.ckpt&quot; 123456train_input_reader: &#123; tf_record_input_reader &#123; input_path: &quot;train_data/train.record&quot; &#125; label_map_path: &quot;training/object-detection.pbtxt&quot; &#125; 最后在object_detection文件夹下：运行命令： 1python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config train_dir: 训练输出文件的路径 pipeline_config: 网络配置文件的路径 测试输出模型的准确性 利用.py 转换 .pb From model/research/object_detection 123456python3 export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssd_mobilenet_v1_pets.config --trained_checkpoint_prefix training/model.ckpt-388 --output_directory mac_n_cheese_inference_graph input_type : 保持一致 pipeline: 网络结构配置图 train_checkpoint: ckpt模型保存路径 既上面训练路径的设置位置 out: 输出文件 ####最后利用jupyter notebook加载pb模型进行测试1234567891011121314#修改object_detection_tutorial.ipynb# What model to download.MODEL_NAME = &apos;mac_n_cheese_inference_graph&apos;#Path to frozen detection graph. This is the actual model that is used for the object detection.PATH_TO_CKPT = MODEL_NAME + &apos;/frozen_inference_graph.pb&apos;# List of the strings that is used to add correct label for each box.PATH_TO_LABELS = os.path.join(&apos;training&apos;, &apos;object-detection.pbtxt&apos;)NUM_CLASSES = 1#删除downloand程序，修改加载测试图片的路径，运行即可 所有的配置文件在： https://github.com/junqiangwu/My_Tensorflow/tree/master/object-detection]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mxnet2Caffe]]></title>
    <url>%2F2019%2F03%2F10%2FMxnet2Caffe%2F</url>
    <content type="text"><![CDATA[Mxnet2Caffe 将mxnet静态图symbol转换为caffe的prototxt文本，支持大部分op，caffe不需要的op则需要自己添加，再转换，否则会构建失败 将json转换为prototxt 利用caffe的python接口构建网络，将mxnet的参数param迁移到caffe网络中 构建caffe不支持的op 对结果进行比对 json_2_protxt json2prototxt.py prototxt_basic.py Read mxnet_json file and converte to prototxt 123456789101112131415161718192021222324252627282930313233// json 格式，只要就是op(操作节点和辅助节点null) name attr(参数列表) inputs(输入列表list) &#123; "op": "Activation", "name": "part_0_stage1_unit1_relu1", "attrs": &#123;"act_type": "relu"&#125;, "inputs": [[14, 0, 0]] &#125;, &#123; "op": "null", "name": "part_0_stage1_unit1_conv1_weight", "attrs": &#123; "kernel": "(3, 3)", "no_bias": "True", "num_filter": "64", "pad": "(1, 1)", "stride": "(1, 1)", "workspace": "256" &#125;, "inputs": [] &#125;, &#123; "op": "Convolution", "name": "part_0_stage1_unit1_conv1", "attrs": &#123; "kernel": "(3, 3)", "no_bias": "True", "num_filter": "64", "pad": "(1, 1)", "stride": "(1, 1)", "workspace": "256" &#125;, "inputs": [[15, 0, 0], [16, 0, 0]] &#125;, 读取json文件，并存储相应信息12345678910111213141516171819202122232425262728293031323334353637with open(args.mx_json) as json_file: jdata = json.load(json_file)with open(args.cf_prototxt, "w") as prototxt_file: for i_node in range(0,len(jdata['nodes'])): #logging.info("i_node[%d],'name' %s" %(i_node,jdata['nodes'][i_node]['name'])) node_i = jdata['nodes'][i_node] # 如果当前节点是辅助节点或输入节点(只转换操作节点) 则跳过 if str(node_i['op']) == 'null' and str(node_i['name']) != 'data': continue ''' logging.info('%d, \top:%s, name:%s -&gt; %s'.%(i_node,node_i['op'].ljust(20), node_i['name'].ljust(30), node_i['name']).ljust(20)) ''' ##node[i]个节点 存在的信息 op name param input info = node_i info['top'] = info['name'] info['bottom'] = [] info['params'] = [] # 遍历当前节点的输入 存储辅助参数 for input_idx_i in node_i['inputs']: # jdata['nodes'][input_idx_i[0]] jdana['nodes'][input_index] input_i = jdata['nodes'][input_idx_i[0]] #存储所有输入节点 if str(input_i['op']) != 'null' or (str(input_i['name']) == 'data'): info['bottom'].append(str(input_i['name'])) if str(input_i['op']) == 'null': info['params'].append(str(input_i['name'])) if not str(input_i['name']).startswith(str(node_i['name'])): logging.info(' use shared weight -&gt; %s'% str(input_i['name'])) info['share'] = True write_node(prototxt_file, info) 写prototxt文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# 转换 Convolution 节点操作def Convolution(txt_file, info): if info['attrs']['no_bias'] == 'True': bias_term = 'false' else: bias_term = 'true' txt_file.write('layer &#123;\n') txt_file.write(' bottom: "%s"\n' % info['bottom'][0]) txt_file.write(' top: "%s"\n' % info['top']) txt_file.write(' name: "%s"\n' % info['top']) txt_file.write(' type: "Convolution"\n') txt_file.write(' convolution_param &#123;\n') txt_file.write(' num_output: %s\n' % info['attrs']['num_filter']) txt_file.write(' kernel_size: %s\n' % info['attrs']['kernel'].split('(')[1].split(',')[0]) # TODO if 'pad' not in info['attrs']: logging.info('miss Conv_pad, make pad default: 0 ') txt_file.write(' pad: %s\n' % 0) # TODO else: txt_file.write(' pad: %s\n' % info['attrs']['pad'].split('(')[1].split(',')[0]) # TODO# txt_file.write(' group: %s\n' % info['attrs']['num_group']) txt_file.write(' stride: %s\n' % info['attrs']['stride'].split('(')[1].split(',')[0]) txt_file.write(' bias_term: %s\n' % bias_term) txt_file.write(' &#125;\n') if 'share' in info.keys() and info['share']: txt_file.write(' param &#123;\n') txt_file.write(' name: "%s"\n' % info['params'][0]) txt_file.write(' &#125;\n') txt_file.write('&#125;\n') txt_file.write('\n')# -------根据op操作，完善相应的转换函数-----------# 目前包含Conv Pool DepthConv BN Act ele_add Concat FC Reshape etc. def write_node(txt_file, info): if 'label' in info['name']: return if info['op'] == 'null' and info['name'] == 'data': data(txt_file, info) elif info['op'] == 'Convolution': Convolution(txt_file, info) elif info['op'] == 'ChannelwiseConvolution': ChannelwiseConvolution(txt_file, info) elif info['op'] == 'BatchNorm': BatchNorm(txt_file, info) elif info['op'] == 'Activation': Activation(txt_file, info)# elif info['op'] == 'ElementWiseSum': elif info['op'] == 'elemwise_add': ElementWiseSum(txt_file, info) elif info['op'] == '_Plus': ElementWiseSum(txt_file, info) elif info['op'] == 'Concat': Concat(txt_file, info) elif info['op'] == 'Pooling':# Pooling(txt_file, info) Pooling_global(txt_file, info) elif info['op'] == 'Flatten': Flatten(txt_file, info) elif info['op'] == 'FullyConnected': FullyConnected(txt_file, info) elif info['op'] == 'SoftmaxOutput': SoftmaxOutput(txt_file, info) elif info['op'] == 'Cast': Cast(txt_file, info) elif info['op'] == 'SliceChannel': SliceChannel(txt_file, info) elif info['op'] == 'L2Normalization': L2Normalization(txt_file, info) elif info['op'] == 'Reshape': Reshape(txt_file,info) elif info['op'] == 'broadcast_mul': broadcast_mul(txt_file,info) else: logging.warn("Unknown mxnet op: %s" %info['op']) 利用caffe的python接口，构建网络，并迁移mxnet的网络参数1.mxnet2caffe.py Read mxnet_model params_dict and converte to .caffemodel 转换的时候如果存在caffe不支持的op，需要自己添加自定义层，否则在构建网络时，会error，本工程添加了broadcast_mul层caffe添加自定义层的介绍比较多，就跳过了 根据mxnet的API (load) 加载param文件的所有参数字典12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152try: import caffeexcept ImportError: import os, sys sys.path.append("/home/***/codes/mx2caffe/caffe/python/") import caffe#读取全部param 参数字典 _, arg_params, aux_params = mx.model.load_checkpoint(args.mx_model, args.mx_epoch)all_keys = arg_params.keys() + aux_params.keys()# 利用caffe的python接口，读取刚转换的proto构建网络，net = caffe.Net(args.cf_prototxt, caffe.TRAIN)for i_key,key_i in enumerate(all_keys): try: if 'data' is key_i: pass # 在mxnet字典中，存有caffe不需要的后缀，_weight _bias # 需要确认caffe的参数保存顺序 [0]是weight [1]是bias 其它op 类似查看proto结构设计 elif '_weight' in key_i: key_caffe = key_i.replace('_weight','') net.params[key_caffe][0].data.flat = arg_params[key_i].asnumpy().flat elif '_bias' in key_i: key_caffe = key_i.replace('_bias','') net.params[key_caffe][1].data.flat = arg_params[key_i].asnumpy().flat elif '_gamma' in key_i: key_caffe = key_i.replace('_gamma','_scale') net.params[key_caffe][0].data.flat = arg_params[key_i].asnumpy().flat elif '_beta' in key_i: key_caffe = key_i.replace('_beta','_scale') net.params[key_caffe][1].data.flat = arg_params[key_i].asnumpy().flat elif '_moving_mean' in key_i: key_caffe = key_i.replace('_moving_mean','') net.params[key_caffe][0].data.flat = aux_params[key_i].asnumpy().flat net.params[key_caffe][2].data[...] = 1 elif '_moving_var' in key_i: key_caffe = key_i.replace('_moving_var','') net.params[key_caffe][1].data.flat = aux_params[key_i].asnumpy().flat net.params[key_caffe][2].data[...] = 1 else: sys.exit("Warning! Unknown mxnet:&#123;&#125;".format(key_i)) print("% 3d | %s -&gt; %s, initialized." %(i_key, key_i.ljust(40), key_caffe.ljust(30))) except KeyError: print("\nWarning! key error mxnet:&#123;&#125;".format(key_i)) # ------------------------------------------# Finishnet.save(args.cf_model)print("\n- Finished.\n") 对转换结果进行比对确认 mxnet_test.py Debug mxnet output and you can compare the result with the converted caffemodel 使用mxnet debug， 打印需要对比的参数，并且输出指定层的结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import mxnet as mxdef load_checkpoint_single(model, param_path): arg_params = &#123;&#125; aux_params = &#123;&#125; save_dict = mx.nd.load(param_path) for k, value in save_dict.items(): arg_type, name = k.split(':', 1) if arg_type == 'arg': arg_params[name] = value if arg_type == 'aux': aux_params[name] = value else : pass model.set_params(arg_params, aux_params, allow_missing=False) arg_params, aux_params = model.get_params() return arg_params, aux_paramsfull_param_path = 'se_resnet34/base-0000.params'fmodel = mx.sym.load('se_resnet34/base-symbol.json')# 获取mxnet网络的所有layer参数all_layers = fmodel.get_internals()# 修改这里为需要输出layer的name+output即可指定层输出 ‘name_output’fmodel = all_layers['flat_output']fullmodel = mx.mod.Module(symbol=fmodel,data_names=['data'],label_names=[])img = []img = get_image_gray('before_forward.jpg')fullmodel.bind(data_shapes=[('data', (1, 1, 108, 108))], label_shapes=None, for_training=False, force_rebind=False)arg_params, aux_params = load_checkpoint_single(fullmodel, full_param_path)fullmodel.set_params(arg_params,aux_params)file1=open('se_resnet34.txt','w')tic=time.time()fullmodel.forward(Batch([mx.nd.array(img)]))prob = fullmodel.get_outputs()[0].asnumpy()prob = prob.astype(np.float64)prob = prob.reshape(-1,1)# 以特定的格式保存结果np.savetxt(file1,prob,fmt='%.12f')file1.close() 然后利用Caffe 加载刚才转换的网络，打印输出，对比结果精度，如果出现问题，则需要逐层排查，本工程在SENet网络上测试正常 工程项目地址 https://github.com/junqiangwu/Mxnet2Caffe-Tensor-RT-SEnet TODO: add caffe_plugin_layer Tensor RT load caffe_model Tensor RT supported Se_Resnet]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Mxnet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NAS (Neural Architecture Search)]]></title>
    <url>%2F2019%2F03%2F09%2FFBNET%2F</url>
    <content type="text"><![CDATA[NAS(Neural Architecture Search)FBNet Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture SearchImplementation of FBNet with MXNet paper address: https://arxiv.org/pdf/1812.03443.pdf Implemented Net: FBNet FBNet Based on Se_Resnet_50_Architecture other block_type architecture cound be easily implement by modify fbnet-symbol/block.py Code: blocks.py: Define blocks symbols FBNet.py: Define FBNet Class. FBNet_SE.py: Define FBNet Architecture based on Se_resnet_50. blocks_se.py: Define blocks symbols based on new search space,include [Resnet_50,Se,Group_Conv,Channel_shuffle,Deform_Conv] util.py: Define some functions. test.py: Run test. block_speed_test.py: test block lat in real environment(1080Ti) Differences from original paper: The last conv layer’s num_filters is repalced by feature_dim specified by paramters Use Amsoftmax, Arcface instead of FC, but you can set model_type to softamx to use fc Default input shape is 3,108,108, so the first conv layer has stride 1 instead of 2. Add BN out of blocks, and no bn inside blocks. Last conv has kernel size 3,3 Use + in loss not *. Adding gradient rising stage in cosine decaying schedule. Code in fbnet-symbom/util/CosineDecayScheduler_Grad How to train:If you want to modify the network structure or the learning rate adjustment function, you need to modify the source code,otherwise you can use this command directly: 1python test.py --gpu 0,1,2,3,4,5,6 --log-frequence 50 --model-type softmax --batch-size 32 How to retrain:When we want to train the large dataset and hope to change learning rate manually, or the machine is suddenly shutdown due to some reason,of course, we definitely hope we can continue to train model with previous trained weights. Then, your can use this cmd: 1python test.py --gpu 0,1,2,3,4,5,6 --log-frequence 50 --model-type softmax --batch-size 32 --load-model-path ./model This can load the latest model params for retrain,If you want to load the model with specific epoch,you can use –load-model-path ./model/*.params ,This means you can retrain your model from specific model. TODO: sample script, for now just save $\theta$ cosine decaying schedule lat in real environment DataParallel implementation]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>NAS</tag>
      </tags>
  </entry>
</search>
